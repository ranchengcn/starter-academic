
@article{noauthor_notitle_nodate,
}

@article{noauthor_notitle_nodate-1,
}

@inproceedings{cheng_multi-swarm_2013,
	title = {A {Multi}-swarm {Evolutionary} {Framework} based on a {Feedback} {Mechanism}},
	doi = {10.1109/CEC.2013.6557639},
	abstract = {Most evolutionary algorithms, including particle swarm optimization (PSO) algorithms, involve at least one population (swarm) to realize information exchange or information sharing among different individuals. To enhance the algorithms' global search ability, several multi-swarm PSO algorithms have been proposed. In this paper, a novel multi-swarm evolutionary framework based on a feedback mechanism is introduced. The framework consists of a search operator similar to those in PSO and a mutation strategy, on the top of the feedback mechanism. The framework is compared with a multi-swarm PSO and the canonical PSO on a few widely used benchmarks to demonstrate its performance.},
	booktitle = {2013 {IEEE} {Congress} on {Evolutionary} {Computation}},
	author = {Cheng, Ran and Sun, Chaoli and Jin, Yaochu},
	year = {2013},
	keywords = {Convergence, Evolutionary computation, Optimization, Search problems, Sociology, Statistics, Vectors},
	pages = {718--724},
}

@inproceedings{cheng_simulating_2013,
	title = {Simulating {Swarm} {Behaviuors} for {Optimisation} by {Learning} from {Neighbours}},
	doi = {10.1109/UKCI.2013.6651291},
	abstract = {Competitive particle swarm optimizer (ComPSO) is a novel swarm intelligence algorithm that does not need any memory. Different from the canonical particle swarm optimizer (PSO), neither gbest nor pbest needs to be stored in ComPSO, and the algorithm is extremely simple in implementation. ComPSO has shown to be highly scalable to the search dimension. In the original ComPSO, two particles are randomly chosen to compete. This work investigates the influence of the competition rule on the search performance of ComPSO and proposes a new competition rule operating on a sorted swarm with neighborhood control. Empirical studies have been performed on a set of widely used test functions to compare the new competition rule with the random strategy. Results show that the new competition rule can speed up the convergence with a big neighborhood size, while with a small neighborhood size, the convergence speed can be slowed down.},
	booktitle = {2013 13th {UK} {Workshop} on {Computational} {Intelligence} ({UKCI})},
	author = {Cheng, Ran and Jin, Yaochu},
	year = {2013},
	keywords = {Convergence, Optimization, Sociology, Statistics, Aerospace electronics, Educational institutions, Particle swarm optimization},
	pages = {82--87},
}

@inproceedings{cheng_adaptive_2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adaptive {Reference} {Vector} {Generation} for {Inverse} {Model} {Based} {Evolutionary} {Multiobjective} {Optimization} with {Degenerate} and {Disconnected} {Pareto} {Fronts}},
	isbn = {978-3-319-15934-8},
	doi = {10.1007/978-3-319-15934-8_9},
	abstract = {Inverse model based multiobjective evolutionary algorithm aims to sample candidate solutions directly in the objective space, which makes it easier to control the diversity of non-dominated solutions in multiobjective optimization. To facilitate the process of inverse modeling, the objective space is partitioned into several subregions by predefining a set of reference vectors. In the previous work, the reference vectors are uniformly distributed in the objective space. Uniformly distributed reference vectors, however, may not be efficient for problems that have nonuniform or disconnected Pareto fronts. To address this issue, an adaptive reference vector generation strategy is proposed in this work. The basic idea of the proposed strategy is to adaptively adjust the reference vectors according to the distribution of the candidate solutions in the objective space. The proposed strategy consists of two phases in the search procedure. In the first phase, the adaptive strategy promotes the population diversity for better exploration, while in the second phase, the strategy focused on convergence for better exploitation. To assess the performance of the proposed strategy, empirical simulations are carried out on two DTLZ benchmark problems, namely, DTLZ5 and DTLZ7, which have a degenerate and a disconnected Pareto front, respectively. Our results show that the proposed adaptive reference vector strategy is promising in tacking multiobjective optimization problems whose Pareto front is disconnected.},
	language = {en},
	booktitle = {Evolutionary {Multi}-{Criterion} {Optimization}},
	publisher = {Springer International Publishing},
	author = {Cheng, Ran and Jin, Yaochu and Narukawa, Kaname},
	editor = {Gaspar-Cunha, Ant√≥nio and Henggeler Antunes, Carlos and Coello, Carlos Coello},
	year = {2015},
	keywords = {Inverse modeling, Model based evolutionary optimization, Multiobjective optimization, Reference vectors},
	pages = {127--140},
}

@inproceedings{cheng_reference_2015,
	title = {Reference {Vector} {Based} a posteriori {Preference} {Articulation} for {Evolutionary} {Multiobjective} {Optimization}},
	doi = {10.1109/CEC.2015.7256991},
	abstract = {Multiobjective evolutionary algorithms (MOEAs) usually achieve a set of nondominated solutions as the approximation of the Pareto front. In order to utilize the solutions, a final decision making process is indispensable in most cases in which a small number of solutions have to be selected. In this process a decision maker selects the solutions according to his or her preferences or based on the knowledge acquired by observing the approximated Pareto front. Due to the limited number of solutions an algorithm can obtain, in particular when the number of objectives is large, a decision maker may be interested in sampling additional solutions in some preferred regions. This paper proposes to use a reference vector based preference articulation (RVPA) method to obtain such additional solutions in preferred regions. After describing the proposed method in detail, experiments are conducted on six benchmark MOPs to assess the performance of the proposed RVPA method. Our empirical results show that, by setting reference vectors in the objective space, the proposed RVPA is able to obtain corresponding solutions in the preferred regions at a much lower cost compared to e.g. a re-start strategy. In addition, by setting the reference vectors in a uniform way, the proposed RVPA method is also able to improve the general quality (convergence and distribution) of the solutions obtained by an MOEA.},
	booktitle = {2015 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Cheng, Ran and Olhofer, Markus and Jin, Yaochu},
	year = {2015},
	keywords = {Evolutionary computation, Sociology, Benchmark testing, Decision making, Electronic mail, Pareto optimization},
	pages = {939--946},
}

@inproceedings{carneiro_network_2016,
	title = {Network {Structural} {Optimization} {Based} on {Swarm} {Intelligence} for {Highlevel} {Classification}},
	doi = {10.1109/IJCNN.2016.7727681},
	abstract = {While most part of the complex network models are described in function of some growth mechanism, the optimization of a goal or certain characteristics can be desirable for some problems. This paper investigates structural optimization of networks in the highlevel classification context, where the classification produced by a traditional classifier is combined with the classification provided by complex network measures. Using the recently proposed social learning particle swarm optimization (SL-PSO), a bio-inspired optimization framework, which is responsible to build up the network and adjust the parameters of the hybrid model while conducting the optimization of a quality function, is proposed. Experiments on two real-world problems, the Handwritten Digits Recognition and the Semantic Role Labeling (SRL), were performed. In both problems, the optimization framework is able to improve the classification given by a state-of-the-art algorithm to SRL. Furthermore, the optimization framework proposed here can be extended to other machine learning tasks.},
	booktitle = {2016 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Carneiro, Murillo G. and Zhao, Liang and Cheng, Ran and Jin, Yaochu},
	year = {2016},
	keywords = {Optimization, Particle swarm optimization, Biological system modeling, Complex networks, Mathematical model, Supervised learning, Training data},
	pages = {3737--3744},
}

@inproceedings{cheng_demonstrator_2014,
	title = {Demonstrator {Selection} in a {Social} {Learning} {Particle} {Swarm} {Optimizer}},
	doi = {10.1109/CEC.2014.6900227},
	abstract = {Social learning plays an important role in behavior learning among social animals. Different from individual (asocial) learning, social learning has the advantage of allowing individuals to learn behaviors from others without the extra costs of individual trial-and-error. Inspired by the natural social learning phenomenon, we have transplanted the social learning mechanism into particle swarm optimization (PSO) to develop a social learning PSO (SL-PSO). Unlike classical PSO variants, the SL-PSO is performed on a sorted swarm, and instead of merely learning from historical best positions, the particles are able to learn from anyone better (demonstrators) in the current swarm. A key mechanism in the SL-PSO is the learning strategy, where an imitator will learn from different demonstrators. However, in our previous work, little discussion has been focused on demonstrator selection, i.e., which demonstrators are to learn from by the imitator. In this paper, based on the analysis of the demonstrator selection in the SL-PSO, two demonstrator selection strategies are proposed. Experimental results show that, the proposed demonstrator selection strategies have significantly enhanced the performance of the SL-PSO in comparison to five representative PSO variants on a set of benchmark problems.},
	booktitle = {2014 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Cheng, Ran and Jin, Yaochu},
	year = {2014},
	keywords = {Sociology, Statistics, Particle swarm optimization, Benchmark testing, Gaussian distribution, Indexes, Learning systems},
	pages = {3103--3110},
}

@inproceedings{zhang_empirical_2016,
	title = {Empirical {Analysis} of a {Tree}-based {Efficient} {Non}-dominated {Sorting} {Approach} for {Many}-objective {Optimization}},
	doi = {10.1109/SSCI.2016.7850210},
	abstract = {Non-dominated sorting has been widely adopted in evolutionary multi-objective optimization. Many approaches to non-dominated sorting have been proposed to improve its computational efficiency, but unfortunately, most of them still suffer from high computational cost, especially when the number of objectives becomes large. A tree-based efficient non-dominated sorting approach, termed T-ENS, has been recently developed by us for many-objective optimization, where a tree structure is adopted to represent solutions, such that the non-dominance relationship between solutions can be easily inferred from the position of the solutions in the tree, thereby considerably reducing the number of comparisons between solutions belonging to the same non-dominated front. To validate the computational efficiency of T-ENS, this paper provides a detailed empirical analysis by comparing T-ENS with the state-of-the-art approaches, in particular when the number of objectives is larger than three and the population size becomes large. Empirical results indicate that the T-ENS is well suited for evolutionary many-objective optimization and large-scale multi-objective optimization, where either the number of objectives or the population size is large.},
	booktitle = {2016 {IEEE} {Symposium} {Series} on {Computational} {Intelligence} ({SSCI})},
	author = {Zhang, Xingyi and Tian, Ye and Cheng, Ran and Jin, Yaochu},
	year = {2016},
	keywords = {Optimization, Sociology, Statistics, Computer science, Sorting, Time complexity},
	pages = {1--8},
}

@inproceedings{tian_multi-objective_2016,
	title = {A {Multi}-objective {Evolutionary} {Algorithm} {Based} on an {Enhanced} {Inverted} {Generational} {Distance} {Metric}},
	doi = {10.1109/CEC.2016.7748352},
	abstract = {As a pivotal component in multi-objective evolutionary algorithms (MOEAs), the environmental selection determines the quality of candidate solutions to survive at each generation. In practice, different environmental selection strategies can be based on different selection criteria, where the performance metrics (or indicators) are shown to be among the most effective ones. This paper proposes an MOEA whose environmental selection is based on an enhanced inverted generational distance metric that is able to detect noncontributing solutions (termed IGD-NS), thereby considerably accelerating the convergence of the evolutionary search. Experimental results on ZDT and DTLZ test suites demonstrate the competitive performance of the proposed MOEA/IGD-NS in comparison with some representative MOEAs.},
	booktitle = {2016 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Tian, Ye and Zhang, Xingyi and Cheng, Ran and Jin, Yaochu},
	year = {2016},
	keywords = {Convergence, Evolutionary computation, Sociology, Pareto optimization, Measurement},
	pages = {5222--5229},
}

@article{wang_data-driven_2017,
	series = {20th {IFAC} {World} {Congress}},
	title = {Data-{Driven} {Surrogate}-{Assisted} {Multi}-{Objective} {Optimization} of {Complex} {Beneficiation} {Operational} {Process}},
	volume = {50},
	issn = {2405-8963},
	url = {https://www.sciencedirect.com/science/article/pii/S2405896317334882},
	doi = {10.1016/j.ifacol.2017.08.2561},
	abstract = {Most optimization algorithms suppose that there exist explicit evaluation functions to evaluate the candidate solutions obtained during the optimization process. However, in actual industrial processes, it is usually very difficult to build up precise mathematical models to describe complex industrial processes due to the lack of clear mechanisms. Instead, only some noisy historical data can be used, and optimization of such problem is often known as data-driven optimization. The optimization of complex beneficiation operational process is a typical data-driven optimization problem. To solve this problem, an evolutionary algorithm assisted by Gaussian process model is proposed in this paper. To be specific, a low-order neural network model is constructed by using the data collected from mineral processing factory as real objective function, and a Gaussian process model is developed as a surrogate to reduce the number of real function evaluations. We test the new method on a series of multi-objective test instances against two other algorithms. The experimental results indicate that the proposed method has the ability to achieve significant improvement at the limited budget of real function evaluations. In addition, the proposed algorithm is also successfully applied to the optimization of complex beneficiation operational process.},
	language = {en},
	number = {1},
	urldate = {2021-08-01},
	journal = {IFAC-PapersOnLine},
	author = {Wang, Chengzhi and Ding, Jinliang and Cheng, Ran and Liu, Changxin and Chai, Tianyou},
	year = {2017},
	keywords = {beneficiation process, data-driven optimization, Gaussian process model, multi-objective optimization, operational optimization, surrogate-assisted},
	pages = {14982--14987},
}

@inproceedings{cheng_parallel_2017,
	title = {Parallel {Peaks}: {A} {Visualization} {Method} for {Benchmark} {Studies} of {Multimodal} {Optimization}},
	shorttitle = {Parallel peaks},
	doi = {10.1109/CEC.2017.7969322},
	abstract = {Multimodal optimization has attracted increasing interest recently. Despite the emergence of various multimodal optimization algorithms during the last decade, little work has been dedicated to the development of benchmark tools. In this paper, we propose a visualization method for benchmark studies of multimodal optimization, called parallel peaks. Inspired by parallel coordinates, the proposed parallel peaks method is capable of visualizing both distribution information and convergence information of a given candidate solution set inside a 2D coordinate plane. To the best of our knowledge, this is the first visualization method in the multimodal optimization area. Our empirical results demonstrate that the proposed parallel peaks method can be robustly used to visualize candidate solutions sets with a range of properties, including high-accuracy solutions sets, high-dimensional solution sets and solution sets with a large number of optima. Additionally, by visualizing the populations obtained during the optimization process, it can also be used to investigate search behaviors of multimodal optimization algorithms.},
	booktitle = {2017 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Cheng, Ran and Li, Miqing and Yao, Xin},
	year = {2017},
	keywords = {Optimization, Sociology, Statistics, Benchmark testing, Data visualization, Two dimensional displays, Visualization},
	pages = {263--270},
}

@inproceedings{zhen_adjusting_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adjusting {Parallel} {Coordinates} for {Investigating} {Multi}-objective {Search}},
	isbn = {978-3-319-68759-9},
	doi = {10.1007/978-3-319-68759-9_19},
	abstract = {Visualizing a high-dimensional solution set over the evolution process is a viable way to investigate the search behavior of evolutionary multi-objective optimization. The parallel coordinates plot which scales well to the data dimensionality is frequently used to observe solution sets in multi-objective optimization. However, the solution sets in parallel coordinates are typically presented by the natural order of the optimized objectives, with rare information of the relation between these objectives and also the Pareto dominance relation between solutions. In this paper, we attempt to adjust parallel coordinates to incorporate this information. Systematic experiments have shown the effectiveness of the proposed method.},
	language = {en},
	booktitle = {Simulated {Evolution} and {Learning}},
	publisher = {Springer International Publishing},
	author = {Zhen, Liangli and Li, Miqing and Cheng, Ran and Peng, Dezhong and Yao, Xin},
	editor = {Shi, Yuhui and Tan, Kay Chen and Zhang, Mengjie and Tang, Ke and Li, Xiaodong and Zhang, Qingfu and Tan, Ying and Middendorf, Martin and Jin, Yaochu},
	year = {2017},
	pages = {224--235},
}

@inproceedings{he_surrogate-assisted_2019,
	title = {Surrogate-{Assisted} {Expensive} {Many}-{Objective} {Optimization} by {Model} {Fusion}},
	doi = {10.1109/CEC.2019.8790155},
	abstract = {Surrogate-assisted evolutionary algorithms have played an important role in expensive optimization where a small number of real-objective function evaluations are allowed. Usually, the surrogate models are used for the same purpose, e.g., to approximate the real-objective function or the aggregation fitness function. However, there is little work on surrogate-assisted optimization by model fusion, i.e., different surrogate models are fused for different purposes to improve the performance of the algorithm. In this work, we propose a surrogate-assisted approach by model fusion for solving expensive many-objective optimization problems, in which the Kriging assisted objective function approximation method is fused with the classifier assisted approach. The proposed algorithm is compared with some state-of-the-art surrogate-assisted algorithms on DTLZ problems and a real-world problem, and some encouraging results have been achieved by our proposed model fusion based approach.},
	booktitle = {2019 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {He, Cheng and Cheng, Ran and Jin, Yaochu and Yao, Xin},
	year = {2019},
	keywords = {Evolutionary computation, Optimization, Sociology, Statistics, Approximation algorithms, classification, Computational modeling, Expensive problem, fitness approximation, Kriging, many-objective optimization, model fusion, surrogate-assisted optimization, Uncertainty},
	pages = {1672--1679},
}

@inproceedings{tian_sampling_2018,
	title = {Sampling {Reference} {Points} on the {Pareto} {Fronts} of {Benchmark} {Multi}-{Objective} {Optimization} {Problems}},
	doi = {10.1109/CEC.2018.8477730},
	abstract = {The effectiveness of evolutionary algorithms have been verified on multi-objective optimization, and a large number of multi-objective evolutionary algorithms have been proposed during the last two decades. To quantitatively compare the performance of different algorithms, a set of uniformly distributed reference points sampled on the Pareto fronts of benchmark problems are needed in the calculation of many performance metrics. However, not much work has been done to investigate the method for sampling reference points on Pareto fronts, even though it is not an easy task for many Pareto fronts with irregular shapes. More recently, an evolutionary multi-objective optimization platform was proposed by us, called PlatEMO, which can automatically generate reference points on each Pareto front and use them to calculate the performance metric values. In this paper, we report the reference point sampling methods used in PlatEMO for different types of Pareto fronts. Experimental results show that the reference points generated by the proposed sampling methods can evaluate the performance of algorithms more accurately than randomly sampled reference points.},
	booktitle = {2018 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Tian, Ye and Xiang, Xiaoshu and Zhang, Xingyi and Cheng, Ran and Jin, Yaochu},
	year = {2018},
	keywords = {Evolutionary computation, Optimization, Benchmark testing, Computer science, Measurement, Hypercubes, Sampling methods},
	pages = {1--6},
}

@inproceedings{carneiro_nature-inspired_2017,
	title = {Nature-{Inspired} {Graph} {Optimization} for {Dimensionality} {Reduction}},
	doi = {10.1109/ICTAI.2017.00170},
	abstract = {Graph-based dimensionality reduction has attracted a lot of attention in recent years. Such methods aim to exploit the graph representation in order to catch some structural information hidden in data. They usually consist of two steps: graph construction and projection. Although graph construction is crucial to the performance, most research work in the literature has focused on the development of heuristics and models to the projection step, and only very recently, attention was paid to network construction. In this work, graph construction is considered in the context of supervised dimensionality reduction. To be specific, using a nature-inspired optimization framework, this work investigates if an optimized graph is able to provide better projections than well-known general-purpose methods. The proposed method is compared with widely used graph construction methods on a range of real-world image classification problems. Results show that the optimization framework has achieved considerable dimensionality reduction rates as well as good predictive performance.},
	booktitle = {2017 {IEEE} 29th {International} {Conference} on {Tools} with {Artificial} {Intelligence} ({ICTAI})},
	author = {Carneiro, Murillo G. and Cupertino, Thiago H. and Cheng, Ran and Jin, Yaochu and Zhao, Liang},
	year = {2017},
	keywords = {Optimization, Particle swarm optimization, Training data, Dimensionality reduction, Graph-based dimensionality reduction, graph-based machine learning, Laplace equations, nature-inspired-graph-optimization, Rain, Symmetric matrices},
	pages = {1113--1119},
}

@inproceedings{wan_hybrid_2019,
	title = {A {Hybrid} {Surrogate}-{Assisted} {Evolutionary} {Algorithm} for {Computationally} {Expensive} {Many}-{Objective} {Optimization}},
	doi = {10.1109/CEC.2019.8789913},
	abstract = {Many real-world optimization problems are challenging because the evaluation of solutions is computationally expensive. As a result, the number of function evaluations is limited. Surrogate-assisted evolutionary algorithms are promising approaches to tackle this kind of problems. However, their performance highly depends on the number of objectives. Thus, they may not be suitable for many-objective optimization. This paper proposes a novel hybrid algorithm for computationally expensive many-objective optimization, called C-M-EA. The proposed approach combines two surrogate-assisted evolutionary algorithms during the search process. We compare the performance of the proposed approach with seven multi-objective evolutionary algorithms. Our experimental results show that our approach is competitive for solving computationally expensive many-objective optimization problems.},
	booktitle = {2019 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Wan, Kanzhen and He, Cheng and Camacho, Auraham and Shang, Ke and Cheng, Ran and Ishibuchi, Hisao},
	year = {2019},
	keywords = {Evolutionary computation, Optimization, Sociology, Statistics, Expensive many-objective optimization, Gaussian processes, Hybrid optimization, Iron, Linear programming, Surrogate-assisted evolutionary optimization},
	pages = {2018--2025},
}

@inproceedings{tian_techniques_2020,
	title = {Techniques for {Accelerating} {Multi}-{Objective} {Evolutionary} {Algorithms} in {PlatEMO}},
	doi = {10.1109/CEC48606.2020.9185797},
	abstract = {It has been widely recognized that evolutionary computation is one of the most effective techniques for solving complex optimization problems. As a group of meta-heuristics inspired by nature, the superiority of evolutionary algorithms is mainly attributed to the evolution of multiple candidate solutions, which can strike a balance between exploration and exploitation. However, the effectiveness of evolutionary algorithms is generally at the expense of efficiency, which reduces the prevalence of evolutionary algorithms in solving real-world optimization problems. In 2017, we proposed the evolutionary multi-objective optimization platform PlatEMO to facilitate the use of multi-objective evolutionary algorithms (MOEAs), where some delicate techniques were developed to improve the computational efficiency of MOEAs. These techniques have not been introduced before, since users need not care about them when using existing MOEAs or developing new MOEAs. To deepen the understanding of the core mechanisms of PlatEMO, this paper gives a comprehensive introduction to these techniques, including new non-dominated sorting approaches, matrix calculation, and parallel computing. Several comparative experiments are conducted for a quantitative understanding of the efficiency improvement brought by these techniques.},
	booktitle = {2020 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Tian, Ye and Cheng, Ran and Zhang, Xingyi and Jin, Yaochu},
	year = {2020},
	keywords = {Evolutionary computation, Optimization, Sociology, Statistics, Sorting, Evolution (biology), Runtime},
	pages = {1--8},
}

@inproceedings{he_iterated_2020,
	title = {Iterated {Problem} {Reformulation} for {Evolutionary} {Large}-{Scale} {Multiobjective} {Optimization}},
	doi = {10.1109/CEC48606.2020.9185553},
	abstract = {Due to the curse of dimensionality, two main issues remain challenging for applying evolutionary algorithms (EAs) to large-scale multiobjective optimization. The first issue is how to improve the efficiency of EAs for reducing computation cost. The second one is how to improve the diversity maintenance of EAs to avoid local optima. Nevertheless, these two issues are somehow conflicting with each other, and thus it is crucial to strike a balance between them in practice. Thereby, we propose an iterated problem reformulation based EA for large-scale multiobjective optimization, where the problem reformulation based method and the decomposition based method are used iteratively to address the aforementioned issues. The proposed method is compared with several state-of-the-art EAs on a variety of large-scale multiobjective optimization problems. Experimental results demonstrate the effectiveness of our proposed iterated method in large-scale multiobjective optimization.},
	booktitle = {2020 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {He, Cheng and Cheng, Ran and Tian, Ye and Zhang, Xingyi},
	year = {2020},
	keywords = {Convergence, Sociology, Pareto optimization, Indexes, Computer science, Evolutionary algorithm, large-scale optimization, multiobjective optimization, problem reformulation},
	pages = {1--8},
}

@inproceedings{lin_dimension_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Dimension {Dropout} for {Evolutionary} {High}-{Dimensional} {Expensive} {Multiobjective} {Optimization}},
	isbn = {978-3-030-72062-9},
	doi = {10.1007/978-3-030-72062-9_45},
	abstract = {In the past decades, a number of surrogate-assisted evolutionary algorithms (SAEAs) have been developed to solve expensive multiobjective optimization problems (EMOPs). However, most existing SAEAs focus on low-dimensional optimization problems, since a large number of training samples are required (which is unrealistic for EMOPs) to build an accurate surrogate model for high-dimensional problems. In this paper, an SAEA with Dimension Dropout is proposed to solve high-dimensional EMOPs. At each iteration of the proposed algorithm, it randomly selects a part of the decision variables by Dimension Dropout, and then optimizes the selected decision variables with the assistance of surrogate models. To balance the convergence and diversity, those candidate solutions with good diversity are modified by replacing the selected decision variables with those optimized ones (i.e., decision variables from some better-converged candidate solutions). Eventually, the new candidate solutions are evaluated using expensive functions to update the archive. Empirical studies on ten benchmark problems with up to 200 decision variables demonstrate the competitiveness of the proposed algorithm.},
	language = {en},
	booktitle = {Evolutionary {Multi}-{Criterion} {Optimization}},
	publisher = {Springer International Publishing},
	author = {Lin, Jianqing and He, Cheng and Cheng, Ran},
	editor = {Ishibuchi, Hisao and Zhang, Qingfu and Cheng, Ran and Li, Ke and Li, Hui and Wang, Handing and Zhou, Aimin},
	year = {2021},
	keywords = {Multiobjective optimization, Dimension dropout, High-dimensional, Surrogate-assisted optimization},
	pages = {567--579},
}

@inproceedings{huang_operator-adapted_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Operator-{Adapted} {Evolutionary} {Large}-{Scale} {Multiobjective} {Optimization} for {Voltage} {Transformer} {Ratio} {Error} {Estimation}},
	isbn = {978-3-030-72062-9},
	doi = {10.1007/978-3-030-72062-9_53},
	abstract = {Large-scale multiobjective optimization problems (LSMOPs) exist widely in real-world applications, and they are challenging for existing evolutionary algorithms due to their massive volume of search space. Despite that a number of large-scale multiobjective evolutionary algorithms (LSMOEAs) have been proposed in recent years, their effectiveness in solving LSMOPs remains unsatisfactory. One main reason is that most existing LSMOEAs may fail to balance convergence enhancement and diversity maintenance, especially for solving real-world problems. To address this issue, we propose to use a hybridized LSMOEA with adaptive operator selection (AOS) to handle real-world LSMOPs. Specifically, the proposed hybridized LSMOEA with AOS (AOS-LSMOEA) includes multiple different offspring generation and environmental selection strategies extracted from some existing LSMOEAs. Then it uses the AOS to adaptively determine the application rates of different offspring generation and environmental selection operators in an online manner. The proposed approach is capable of taking advantage of existing LSMOEAs, and the AOS enables the algorithm to choose suitable operators for solving different LSMOPs. In this study, the proposed algorithm is expected to solve the voltage transformer ratio error estimation (TREE) problems effectively. Experimental results show that AOS-LSMOEA achieves significant performance improvement due to the hybridization of different operators and the adoption of AOS method.},
	language = {en},
	booktitle = {Evolutionary {Multi}-{Criterion} {Optimization}},
	publisher = {Springer International Publishing},
	author = {Huang, Changwu and Li, Lianghao and He, Cheng and Cheng, Ran and Yao, Xin},
	editor = {Ishibuchi, Hisao and Zhang, Qingfu and Cheng, Ran and Li, Ke and Li, Hui and Wang, Handing and Zhou, Aimin},
	year = {2021},
	keywords = {Multiobjective optimization, Adaptive operator selection, Large-scale optimization, Voltage transformer ratio error estimation},
	pages = {672--683},
}

@article{pan_manifold_2021,
	title = {Manifold {Learning}-{Inspired} {Mating} {Restriction} for {Evolutionary} {Multiobjective} {Optimization} {With} {Complicated} {Pareto} {Sets}},
	volume = {51},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2019.2952881},
	abstract = {Under certain smoothness assumptions, the Pareto set of a continuous multiobjective optimization problem is a piecewise continuous manifold in the decision space, which can be derived from the Karush‚ÄìKuhn‚ÄìTucker condition. Despite that a number of multiobjective evolutionary algorithms (MOEAs) have been proposed, their performance on multiobjective optimization problems with complicated Pareto sets (MOP-cPS) is still unsatisfying. In this article, we adopt the concept of manifold and propose a manifold learning-inspired mating strategy to enhance the diversity maintenance in MOEAs for solving MOP-cPS efficiently. In the proposed strategy, all of the individuals are first clustered into different manifolds according to their distribution in the objective space, and then the mating reproduction is restricted among individuals in the same manifold. Moreover, we embed the proposed mating strategy in three representative MOEAs and compare the embedded MOEAs with their original versions using the assortative genetic operators on a variety of MOP-cPS. The experimental results demonstrate the significant performance improvements benefitting from the proposed mating restriction strategy.},
	number = {6},
	journal = {IEEE Transactions on Cybernetics},
	author = {Pan, Linqiang and Li, Lianghao and Cheng, Ran and He, Cheng and Tan, Kay Chen},
	year = {2021},
	keywords = {Optimization, Sociology, multiobjective optimization, Assortative crossover, complicated Pareto set, diversity maintenance, Maintenance engineering, manifold learning, Manifolds, mating selection, Principal component analysis, Self-organizing feature maps},
	pages = {3325--3337},
}

@inproceedings{he_population_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Population {Sizing} of {Evolutionary} {Large}-{Scale} {Multiobjective} {Optimization}},
	isbn = {978-3-030-72062-9},
	doi = {10.1007/978-3-030-72062-9_4},
	abstract = {Large-scale multiobjective optimization problems (LSMOPs) are emerging and widely existed in real-world applications, which involve a large number of decision variables and multiple conflicting objectives. Evolutionary algorithms (EAs) are naturally suitable for multiobjective optimization due to their population-based property, allowing the search of optima simultaneously. Nevertheless, LSMOPs are challenging for conventional EAs, mainly due to the huge volume of search space in LSMOPs. Thus, it is important to explore the impact of the population sizing on the performance of conventional multiobjective EAs (MOEAs) in solving LSMOPs. In this work, we compare several representative MOEAs with different settings of population sizes on some transformer ratio error estimation (TREE) problems in the power system. These test cases are defined on combinations of three population sizes, three TREE problems, and five MOEAs. Our results indicate that the performances of conventional MOEAs with different population sizes in solving LSMOPs are different. The impact of population sizing is most significant for differential evolution based and particle swarm based MOEAs.},
	language = {en},
	booktitle = {Evolutionary {Multi}-{Criterion} {Optimization}},
	publisher = {Springer International Publishing},
	author = {He, Cheng and Cheng, Ran},
	editor = {Ishibuchi, Hisao and Zhang, Qingfu and Cheng, Ran and Li, Ke and Li, Hui and Wang, Handing and Zhou, Aimin},
	year = {2021},
	keywords = {Multiobjective optimization, Large-scale optimization, Population size, Transformer ratio error estimation},
	pages = {41--52},
}

@article{he_accelerating_2019,
	title = {Accelerating {Large}-{Scale} {Multiobjective} {Optimization} via {Problem} {Reformulation}},
	volume = {23},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2019.2896002},
	abstract = {In this paper, we propose a framework to accelerate the computational efficiency of evolutionary algorithms on large-scale multiobjective optimization. The main idea is to track the Pareto optimal set (PS) directly via problem reformulation. To begin with, the algorithm obtains a set of reference directions in the decision space and associates them with a set of weight variables for locating the PS. Afterwards, the original large-scale multiobjective optimization problem is reformulated into a low-dimensional single-objective optimization problem. In the reformulated problem, the decision space is reconstructed by the weight variables and the objective space is reduced by an indicator function. Thanks to the low dimensionality of the weight variables and reduced objective space, a set of quasi-optimal solutions can be obtained efficiently. Finally, a multiobjective evolutionary algorithm is used to spread the quasi-optimal solutions over the approximate Pareto optimal front evenly. Experiments have been conducted on a variety of large-scale multiobjective problems with up to 5000 decision variables. Four different types of representative algorithms are embedded into the proposed framework and compared with their original versions, respectively. Furthermore, the proposed framework has been compared with two state-of-the-art algorithms for large-scale multiobjective optimization. The experimental results have demonstrated the significant improvement benefited from the framework in terms of its performance and computational efficiency in large-scale multiobjective optimization.},
	number = {6},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {He, Cheng and Li, Lianghao and Tian, Ye and Zhang, Xingyi and Cheng, Ran and Jin, Yaochu and Yao, Xin},
	year = {2019},
	keywords = {Convergence, Evolutionary computation, Pareto optimization, large-scale optimization, multiobjective optimization, problem reformulation, Acceleration, Evolutionary algorithms, IEEE Fellows, Signal processing algorithms},
	pages = {949--961},
}

@inproceedings{hu_multi-objective_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multi-objective {Neural} {Architecture} {Search} with {Almost} {No} {Training}},
	isbn = {978-3-030-72062-9},
	doi = {10.1007/978-3-030-72062-9_39},
	abstract = {In the recent past, neural architecture search (NAS) has attracted increasing attention from both academia and industries. Despite the steady stream of impressive empirical results, most existing NAS algorithms are computationally prohibitive to execute due to the costly iterations of stochastic gradient descent (SGD) training. In this work, we propose an effective alternative, dubbed Random-Weight Evaluation (RWE), to rapidly estimate the performance of network architectures. By just training the last linear classification layer, RWE reduces the computational cost of evaluating an architecture from hours to seconds. When integrated within an evolutionary multi-objective algorithm, RWE obtains a set of efficient architectures with state-of-the-art performance on CIFAR-10 with less than two hours‚Äô searching on a single GPU card. Ablation studies on rank-order correlations and transfer learning experiments to ImageNet have further validated the effectiveness of RWE.},
	language = {en},
	booktitle = {Evolutionary {Multi}-{Criterion} {Optimization}},
	publisher = {Springer International Publishing},
	author = {Hu, Shengran and Cheng, Ran and He, Cheng and Lu, Zhichao},
	editor = {Ishibuchi, Hisao and Zhang, Qingfu and Cheng, Ran and Li, Ke and Li, Hui and Wang, Handing and Zhou, Aimin},
	year = {2021},
	keywords = {Neural architecture search, Evolutionary algorithms, Multi-objective optimization, Performance estimation},
	pages = {492--503},
}

@article{he_paired_2021,
	title = {Paired {Offspring} {Generation} for {Constrained} {Large}-{Scale} {Multiobjective} {Optimization}},
	volume = {25},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2020.3047835},
	abstract = {Constrained multiobjective optimization problems (CMOPs) widely exist in real-world applications, and they are challenging for conventional evolutionary algorithms (EAs) due to the existence of multiple constraints and objectives. When the number of objectives or decision variables is scaled up in CMOPs, the performance of EAs may degenerate dramatically and may fail to obtain any feasible solutions. To address this issue, we propose a paired offspring generation-based multiobjective EA for constrained large-scale optimization. The general idea is to emphasize the role of offspring generation in reproducing some promising feasible or useful infeasible offspring solutions. We first adopt a small set of reference vectors for constructing several subpopulations with a fixed number of neighborhood solutions. Then, a pairing strategy is adopted to determine some pairwise parent solutions for offspring generation. Consequently, the pairwise parent solutions, which could be infeasible, may guide the generation of well-converged solutions to cross the infeasible region(s) effectively. The proposed algorithm is evaluated on CMOPs with up to 1000 decision variables and ten objectives. Moreover, each component in the proposed algorithm is examined in terms of its effect on the overall algorithmic performance. Experimental results on a variety of existing and our tailored test problems demonstrate the effectiveness of the proposed algorithm in constrained large-scale multiobjective optimization.},
	number = {3},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {He, Cheng and Cheng, Ran and Tian, Ye and Zhang, Xingyi and Tan, Kay Chen and Jin, Yaochu},
	year = {2021},
	keywords = {Convergence, Optimization, Sociology, Statistics, Pareto optimization, many-objective optimization, large-scale optimization, multiobjective optimization, Signal processing algorithms, Constraint handling, evolutionary algorithm (EA)},
	pages = {448--462},
}

@article{chen_solving_2021,
	title = {Solving {Many}-{Objective} {Optimization} {Problems} via {Multistage} {Evolutionary} {Search}},
	volume = {51},
	issn = {2168-2232},
	doi = {10.1109/TSMC.2019.2930737},
	abstract = {With the increase in the number of optimization objectives, balancing the convergence and diversity in evolutionary multiobjective optimization becomes more intractable. So far, a variety of evolutionary algorithms have been proposed to solve many-objective optimization problems (MaOPs) with more than three objectives. Most of the existing algorithms, however, find difficulties in simultaneously counterpoising convergence and diversity during the whole evolutionary process. To address the issue, this paper proposes to solve MaOPs via multistage evolutionary search. To be specific, a two-stage evolutionary algorithm is developed, where the convergence and diversity are highlighted during different search stages to avoid the interferences between them. The first stage pushes multiple subpopulations with different weight vectors to converge to different areas of the Pareto front. After that, the nondominated solutions coming from each subpopulation are selected for generating a new population for the second stage. Moreover, a new environmental selection strategy is designed for the second stage to balance the convergence and diversity close to the Pareto front. This selection strategy evenly divides each objective dimension into a number of intervals, and then one solution having the best convergence in each interval will be retained. To assess the performance of the proposed algorithm, 48 benchmark functions with 7, 10, and 15 objectives are used to make comparisons with five representative many-objective optimization algorithms.},
	number = {6},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	author = {Chen, Huangke and Cheng, Ran and Pedrycz, Witold and Jin, Yaochu},
	year = {2021},
	keywords = {Convergence, Evolutionary computation, Sociology, Pareto optimization, many-objective optimization, Evolutionary algorithm, multistage optimization, Shape},
	pages = {3552--3564},
}

@article{wang_inverse_2021,
	title = {An {Inverse} {Design} {Method} for {Supercritical} {Airfoil} {Based} on {Conditional} {Generative} {Models}},
	issn = {1000-9361},
	url = {https://www.sciencedirect.com/science/article/pii/S1000936121000662},
	doi = {10.1016/j.cja.2021.03.006},
	abstract = {Inverse design has long been an efficient and powerful design tool in the aircraft industry. In this paper, a novel inverse design method for supercritical airfoils is proposed based on generative models in deep learning. A Conditional Variational AutoEncoder (CVAE) and an integrated generative network CVAE-GAN that combines the CVAE with the Wasserstein Generative Adversarial Networks (WGAN), are conducted as generative models. They are used to generate target wall Mach distributions for the inverse design that matches specified features, such as locations of suction peak, shock and aft loading. Qualitative and quantitative results show that both adopted generative models can generate diverse and realistic wall Mach number distributions satisfying the given features. The CVAE-GAN model outperforms the CVAE model and achieves better reconstruction accuracies for all the samples in the dataset. Furthermore, a deep neural network for nonlinear mapping is adopted to obtain the airfoil shape corresponding to the target wall Mach number distribution. The performances of the designed deep neural network are fully demonstrated and a smoothness measurement is proposed to quantify small oscillations in the airfoil surface, proving the authenticity and accuracy of the generated airfoil shapes.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Chinese Journal of Aeronautics},
	author = {Wang, Jing and Li, Runze and He, Cheng and Chen, Haixin and Cheng, Ran and Zhai, Chen and Zhang, Miao},
	year = {2021},
	keywords = {Conditional Variational AutoEncoder (CVAE), Deep learning, Generative Adversarial Networks (GAN), Generative models, Inverse design, Supercritical airfoil},
}

@article{su_parallel_2021,
	title = {A {Parallel} {Multi}-objective {Evolutionary} {Algorithm} for {Community} {Detection} in {Large}-scale {Complex} {Networks}},
	volume = {576},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025521006800},
	doi = {10.1016/j.ins.2021.06.089},
	abstract = {Community detection in large-scale complex networks has recently received significant attention as the volume of available data is becoming larger. The use of evolutionary algorithms (EAs) for community detection in large-scale networks has gained considerable popularity because these algorithms are fairly effective in networks with a relatively small number of nodes. In this paper, we propose a parallel multi-objective EA, called PMOEA, for community detection in large-scale networks, where the communities associated with key network nodes are detected in parallel. Specifically, we develop a multi-objective and a single-objective EA. The former is used to detect the communities of a key node instead of all communities in the network. The latter obtains the communities in the entire network using the previously detected communities of each key node. The performance of the proposed method was verified on both large-scale synthetic benchmark networks and real-world networks. The results demonstrated the superiority of PMOEA over six EA-based and two non-EA-based community-detection algorithms for large-scale networks.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Information Sciences},
	author = {Su, Yansen and Zhou, Kefei and Zhang, Xingyi and Cheng, Ran and Zheng, Chunhou},
	year = {2021},
	keywords = {Evolutionary algorithm, Multi-objective optimization, Community detection, Complex network, Parallel algorithm},
	pages = {374--392},
}

@article{ma_multi-stage_2021,
	title = {A {Multi}-stage {Evolutionary} {Algorithm} for {Multi}-objective {Optimization} with {Complex} {Constraints}},
	volume = {560},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025521000566},
	doi = {10.1016/j.ins.2021.01.029},
	abstract = {Constrained multi-objective optimization problems (CMOPs) are difficult to handle because objectives and constraints need to be considered simultaneously, especially when the constraints are extremely complex. Some recent algorithms work well when dealing with CMOPs with a simple feasible region; however, the effectiveness of most algorithms degrades considerably for CMOPs with complex feasible regions. To address this issue, this paper proposes a multi-stage evolutionary algorithm, where constraints are added one after the other and handled in different stages of evolution. Specifically, in the early stages, the algorithm only considers a small number of constraints, which can make the population efficiently converge to the potential feasible region with good diversity. As the algorithm moves to the later stages, more constraints are considered to search the optimal solutions based on the solutions obtained in the previous stages. Furthermore, a strategy for sorting the constraint-handling priority according to the impact on the unconstrained Pareto front is proposed, which can accelerate the convergence of the algorithm. Experimental results on five benchmark suites and three real-world applications showed that the proposed algorithm outperforms several state-of-the-art constraint multi-objective evolutionary algorithms when dealing with CMOPs, especially for problems with complex constraints.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Information Sciences},
	author = {Ma, Haiping and Wei, Haoyu and Tian, Ye and Cheng, Ran and Zhang, Xingyi},
	year = {2021},
	keywords = {Evolutionary algorithm, Constrained multi-objective optimization, Constraint-handling priority},
	pages = {68--91},
}

@article{yazdani_survey_2021,
	title = {A {Survey} of {Evolutionary} {Continuous} {Dynamic} {Optimization} {Over} {Two} {Decades}‚Äî{Part} {B}},
	volume = {25},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2021.3060012},
	abstract = {This article presents the second Part of a two-Part survey that reviews evolutionary dynamic optimization (EDO) for single-objective unconstrained continuous problems over the last two decades. While in the first part, we reviewed the components of dynamic optimization algorithms (DOAs); in this part, we present an in-depth review of the most commonly used benchmark problems, performance analysis methods, static optimization methods used in the framework of DOAs, and real-world applications. Compared to the previous works, this article provides a new taxonomy for the benchmark problems used in the field based on their baseline functions and dynamics. In addition, this survey classifies the commonly used performance indicators into fitness/error-based and efficiency-based ones. Different types of plots used in the literature for analyzing the performance and behavior of algorithms are also reviewed. Furthermore, the static optimization algorithms that are modified and utilized in the framework of DOAs as the optimization components are covered. We then comprehensively review some real-world dynamic problems that are optimized by EDO methods. Finally, some challenges and opportunities are pointed out for future directions.},
	number = {4},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Yazdani, Danial and Cheng, Ran and Yazdani, Donya and Branke, J√ºrgen and Jin, Yaochu and Yao, Xin},
	year = {2021},
	keywords = {Optimization, Benchmark testing, Computer science, Continuous dynamic real-world problems, dynamic benchmark problems, evolutionary algorithms, future directions, Generators, Heuristic algorithms, Optimization methods, Performance analysis, performance indicators, unconstrained continuous dynamic optimization},
	pages = {630--650},
}

@article{zhang_efficient_2021,
	title = {Efficient {Evolutionary} {Search} of {Attention} {Convolutional} {Networks} via {Sampled} {Training} and {Node} {Inheritance}},
	volume = {25},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2020.3040272},
	abstract = {The performance of deep neural networks is heavily dependent on its architecture and various neural architecture search strategies have been developed for automated network architecture design. Recently, evolutionary neural architecture search (EvoNAS) has received increasing attention due to the attractive global optimization capability of evolutionary algorithms. However, EvoNAS suffers from extremely high computational costs because a large number of performance evaluations are usually required in evolutionary optimization, and training deep neural networks is itself computationally very expensive. To address this issue, this article proposes a computationally efficient framework for the evolutionary search of convolutional networks based on a directed acyclic graph, in which parents are randomly sampled and trained on each mini-batch of training data. In addition, a node inheritance strategy is adopted so that the fitness of all offspring individuals can be evaluated without training them. Finally, we encode a channel attention mechanism in the search space to enhance the feature processing capability of the evolved neural networks. We evaluate the proposed algorithm on the widely used datasets, in comparison with 30 state-of-the-art peer algorithms. Our experimental results show that the proposed algorithm is not only computationally much more efficient but also highly competitive in learning performance.},
	number = {2},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Zhang, Haoyu and Jin, Yaochu and Cheng, Ran and Hao, Kuangrong},
	year = {2021},
	keywords = {Optimization, Sociology, Statistics, Computer architecture, neural architecture search (NAS), Neural networks, Training, Attention mechanism, convolutional neural networks (CNNs), evolutionary optimization, Graphics processing units, node inheritance},
	pages = {371--385},
}

@article{yazdani_adaptive_2020,
	title = {Adaptive {Control} of {Subpopulations} in {Evolutionary} {Dynamic} {Optimization}},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2020.3036100},
	abstract = {Multipopulation methods are highly effective in solving dynamic optimization problems. Three factors affect this significantly: 1) the exclusion mechanisms to avoid the convergence to the same peak by multiple subpopulations; 2) the resource allocation mechanism that assigns the computational resources to the subpopulations; and 3) the control mechanisms to adaptively adjust the number of subpopulations by considering the number of optima and available computational resources. In the existing exclusion mechanisms, when the distance (i.e., the distance between their best found positions) between two subpopulations becomes less than a predefined threshold, the inferior one will be removed/reinitialized. However, this leads to incapability of algorithms in covering peaks/optima that are closer than the threshold. Moreover, despite the importance of resource allocation due to the limited available computational resources between environmental changes, it has not been well studied in the literature. Finally, the number of subpopulations should be adapted to the number of optima. However, in most existing adaptive multipopulation methods, there is no predefined upper bound for generating subpopulations. Consequently, in problems with large numbers of peaks, they can generate too many subpopulations sharing limited computational resources. In this article, a multipopulation framework is proposed to address the aforementioned issues by using three adaptive approaches: 1) subpopulation generation; 2) double-layer exclusion; and 3) computational resource allocation. The experimental results demonstrate the superiority of the proposed framework over several peer approaches in solving various benchmark problems.},
	journal = {IEEE Transactions on Cybernetics},
	author = {Yazdani, Danial and Cheng, Ran and He, Cheng and Branke, J√ºrgen},
	year = {2020},
	keywords = {Sociology, Statistics, Computational resource allocation, dynamic optimization problems (DOPs), Euclidean distance, multipopulation, Resource management, Round robin, Tracking, tracking moving optima (TMO), Upper bound},
	pages = {1--14},
}

@article{yazdani_benchmarking_2020,
	title = {Benchmarking {Continuous} {Dynamic} {Optimization}: {Survey} and {Generalized} {Test} {Suite}},
	issn = {2168-2275},
	shorttitle = {Benchmarking {Continuous} {Dynamic} {Optimization}},
	doi = {10.1109/TCYB.2020.3011828},
	abstract = {Dynamic changes are an important and inescapable aspect of many real-world optimization problems. Designing algorithms to find and track desirable solutions while facing challenges of dynamic optimization problems is an active research topic in the field of swarm and evolutionary computation. To evaluate and compare the performance of algorithms, it is imperative to use a suitable benchmark that generates problem instances with different controllable characteristics. In this article, we give a comprehensive review of existing benchmarks and investigate their shortcomings in capturing different problem features. We then propose a highly configurable benchmark suite, the generalized moving peaks benchmark, capable of generating problem instances whose components have a variety of properties, such as different levels of ill-conditioning, variable interactions, shape, and complexity. Moreover, components generated by the proposed benchmark can be highly dynamic with respect to the gradients, heights, optimum locations, condition numbers, shapes, complexities, and variable interactions. Finally, several well-known optimizers and dynamic optimization algorithms are chosen to solve generated problems by the proposed benchmark. The experimental results show the poor performance of the existing methods in facing new challenges posed by the addition of new properties.},
	journal = {IEEE Transactions on Cybernetics},
	author = {Yazdani, Danial and Omidvar, Mohammad Nabi and Cheng, Ran and Branke, J√ºrgen and Nguyen, Trung Thanh and Yao, Xin},
	year = {2020},
	keywords = {Optimization, Benchmark testing, Linear programming, Shape, Generators, Heuristic algorithms, dynamic optimization problems (DOPs), Complexity theory, Dynamic environments, evolutionary dynamic optimization, moving peaks benchmark (MPB), survey, tracking moving optimum (TMO)},
	pages = {1--14},
}

@article{pan_adaptive_2021,
	title = {Adaptive {Simulated} {Binary} {Crossover} for {Rotated} {Multi}-objective {Optimization}},
	volume = {60},
	issn = {2210-6502},
	url = {https://www.sciencedirect.com/science/article/pii/S2210650220304120},
	doi = {10.1016/j.swevo.2020.100759},
	abstract = {Crossover is a crucial operation for generating promising offspring solutions in evolutionary multi-objective optimization. Among various crossover operators, the simulated binary crossover (SBX) is the most widely used in evolutionary multi-objective optimization. Despite that SBX is effective in solving problems with regular Pareto sets, its performance degenerates dramatically on problems with rotated Pareto sets.To address this issue, we propose a modified SBX, named the rotation-based simulated binary crossover (RSBX), to improve the performance of multi-objective evolutionary algorithms (MOEAs) on rotated problems whose Pareto sets are not parallel with the decision variables. The main idea is to introduce the rotation property into the SBX, and then an adaptive selection strategy is proposed to make use of both SBX and RSBX. The proposed method is embedded in three representative MOEAs, and they are compared with their original versions on some problems with rotated Pareto sets, respectively. Experimental results demonstrate that the proposed method is efficient in promoting the performance of conventional MOEAs for handling rotated multi-objective optimization problems.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Swarm and Evolutionary Computation},
	author = {Pan, Linqiang and Xu, Wenting and Li, Lianghao and He, Cheng and Cheng, Ran},
	year = {2021},
	keywords = {Evolutionary algorithm, Multi-objective optimization, Crossover operator, Rotated problem, Variable linkage},
	pages = {100759},
}

@article{he_evolutionary_2020,
	title = {Evolutionary {Large}-{Scale} {Multiobjective} {Optimization} for {Ratio} {Error} {Estimation} of {Voltage} {Transformers}},
	volume = {24},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2020.2967501},
	abstract = {Ratio error (RE) estimation of the voltage transformers (VTs) plays an important role in modern power delivery systems. Existing RE estimation methods mainly focus on periodical calibration but ignore the time-varying property. Consequently, it is difficult to efficiently estimate the state of the VTs in real time. To address this issue, we formulate a time-varying RE estimation (TREE) problem into a large-scale multiobjective optimization problem, where the multiple objectives and inequality constraints are formulated by statistical and physical rules extracted from the power delivery systems. Furthermore, a set of TREE problems from different substations is systematically formulated into a benchmark test suite for characterizing their different properties. The formulation of these TREE problems not only transfers an expensive RE estimation task to a relatively cheaper optimization problem but also promotes the research in large-scale multiobjective optimization by providing a real-world benchmark test suite with complex variable interactions and correlations to different objectives. To the best of our knowledge, this is the first time to formulate a real-world problem into a benchmark test suite for large-scale multiobjective optimization, and it is also the first work proposing to solve TREE problems via evolutionary multiobjective optimization.},
	number = {5},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {He, Cheng and Cheng, Ran and Zhang, Chuanji and Tian, Ye and Chen, Qin and Yao, Xin},
	year = {2020},
	keywords = {Optimization, Benchmark testing, Estimation, Benchmark test suite, Calibration, Error analysis, inequality constraint, large-scale multiobjective optimization, Substations, time-varying ratio error estimation (TREE), Voltage measurement, voltage transformer (VT)},
	pages = {868--881},
}

@article{hou_reformulating_2020,
	title = {Reformulating {Preferences} into {Constraints} for {Evolutionary} {Multi}- and {Many}-objective {Optimization}},
	volume = {541},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025520305223},
	doi = {10.1016/j.ins.2020.05.103},
	abstract = {Despite that the reference point based preference articulation plays a vital role in evolutionary multi- and many-objective optimization, three issues remain challenging. First, the performance of reference point based preference articulation largely depends on the location of the reference point. Second, the parameter settings for controlling the region of interest are not robust to the Pareto optimal fronts with different complicated shapes. Third, most existing methods have poor scalability to the number of objectives. To meet these challenges, we propose to reformulate preferences into constraints for evolutionary multi- and many-objective optimization. Extensive experiments on a variety of benchmark problems are conducted to demonstrate the effectiveness of our proposed method.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Information Sciences},
	author = {Hou, Zhanglu and He, Cheng and Cheng, Ran},
	year = {2020},
	keywords = {Multiobjective optimization, Constraint handling, Many-objective optimization, Preference articulation},
	pages = {1--15},
}

@article{tian_multistage_2019,
	title = {A {Multistage} {Evolutionary} {Algorithm} for {Better} {Diversity} {Preservation} in {Multiobjective} {Optimization}},
	issn = {2168-2232},
	doi = {10.1109/TSMC.2019.2956288},
	abstract = {Diversity preservation is a crucial technique in multiobjective evolutionary algorithms (MOEAs), which aims at evolving the population toward the Pareto front (PF) with a uniform distribution and a good extensity. In spite of many diversity preservation approaches in existing MOEAs, most of them encounter difficulties in tackling complex PFs. This article gives a detail introduction to existing diversity preservation approaches, as well as a revelation of the limitations of them. To address the limitations of existing diversity preservation approaches, this article proposes a multistage MOEA for better diversity performance. The proposed MOEA divides the optimization process into multiple stages according to the population in each generation, and updates the population by different steady-state selection schemes in different stages. According to the experimental results on 21 benchmark problems, the proposed MOEA exhibits better diversity performance than 11 existing MOEAs.},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	author = {Tian, Ye and He, Cheng and Cheng, Ran and Zhang, Xingyi},
	year = {2019},
	keywords = {Evolutionary computation, Sociology, Pareto optimization, multiobjective optimization, Current measurement, Diversity preservation, evolutionary algorithm, Pareto front (PF), Portfolios},
	pages = {1--15},
}

@article{chen_solving_2020,
	title = {Solving {Large}-scale {Many}-objective {Optimization} {Problems} by {Covariance} {Matrix} {Adaptation} {Evolution} {Strategy} with {Scalable} {Small} {Subpopulations}},
	volume = {509},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025518308041},
	doi = {10.1016/j.ins.2018.10.007},
	abstract = {Despite the recent development in evolutionary multi- and many-objective optimization, the problems with large-scale decision variables still remain challenging. In this work, we propose a scalable small subpopulations based covariance matrix adaptation evolution strategy, namely S3-CMA-ES, for solving many-objective optimization problems with large-scale decision variables. The proposed S3-CMA-ES attempts to approximate the set of Pareto-optimal solutions using a series of small subpopulations instead of a whole population, where each subpopulation converges to only one solution. In the proposed S3-CMA-ES, a diversity improvement strategy is designed to generate and select new solutions. The performance of S3-CMA-ES is compared with five representative algorithms on 36 test instances with 5‚Äì15 objectives and 500‚Äì1500 decision variables. The empirical results demonstrate the superiority of the proposed S3-CMA-ES.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Information Sciences},
	author = {Chen, Huangke and Cheng, Ran and Wen, Jinming and Li, Haifeng and Weng, Jian},
	year = {2020},
	keywords = {Evolutionary algorithm, Many-objective optimization, CMA-ES, Large-scale multi-objective optimization, Scalable populations},
	pages = {457--469},
}

@article{tian_diversity_2019,
	title = {Diversity {Assessment} of {Multi}-{Objective} {Evolutionary} {Algorithms}: {Performance} {Metric} and {Benchmark} {Problems} [{Research} {Frontier}]},
	volume = {14},
	issn = {1556-6048},
	shorttitle = {Diversity {Assessment} of {Multi}-{Objective} {Evolutionary} {Algorithms}},
	doi = {10.1109/MCI.2019.2919398},
	abstract = {Diversity preservation plays an important role in the design of multi-objective evolutionary algorithms, but the diversity performance assessment of these algorithms remains challenging. To address this issue, this paper proposes a performance metric and a multi-objective test suite for the diversity assessment of multiobjective evolutionary algorithms. The proposed metric assesses both the evenness and spread of a solution set by projecting it to a lower-dimensional hypercube and calculating the "volume" of the projected solution set. The proposed test suite contains eight benchmark problems, which pose stiff challenges for existing algorithms to obtain a diverse solution set. Experimental studies demonstrate that the proposed metric can assess the diversity of a solution set more precisely than existing ones, and the proposed test suite can be used to effectively distinguish between algorithms with respect to their diversity performance.},
	number = {3},
	journal = {IEEE Computational Intelligence Magazine},
	author = {Tian, Ye and Cheng, Ran and Zhang, Xingyi and Li, Miqing and Jin, Yaochu},
	year = {2019},
	keywords = {Evolutionary computation, Benchmark testing, Hypercubes},
	pages = {61--74},
}

@article{carneiro_particle_2019,
	title = {Particle {Swarm} {Optimization} for {Network}-{Based} {Data} {Classification}},
	volume = {110},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608018303344},
	doi = {10.1016/j.neunet.2018.12.003},
	abstract = {Complex networks provide a powerful tool for data representation due to its ability to describe the interplay between topological, functional, and dynamical properties of the input data. A fundamental process in network-based (graph-based) data analysis techniques is the network construction from original data usually in vector form. Here, a natural question is: How to construct an ‚Äúoptimal‚Äù network regarding a given processing goal? This paper investigates structural optimization in the context of network-based data classification tasks. To be specific, we propose a particle swarm optimization framework which is responsible for building a network from vector-based data set while optimizing a quality function driven by the classification accuracy. The classification process considers both topological and physical features of the training and test data and employing PageRank measure for classification according to the importance concept of a test instance to each class. Results on artificial and real-world problems reveal that data network generated using structural optimization provides better results in general than those generated by classical network formation methods. Moreover, this investigation suggests that other kinds of network-based machine learning and data mining tasks, such as dimensionality reduction and data clustering, can benefit from the proposed structural optimization method.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Neural Networks},
	author = {Carneiro, Murillo G. and Cheng, Ran and Zhao, Liang and Jin, Yaochu},
	year = {2019},
	keywords = {Complex networks, Data classification, Graph optimization, Machine learning, Network structural optimization, Particle swarm},
	pages = {243--255},
}

@article{cheng_solving_2019,
	title = {Solving {Incremental} {Optimization} {Problems} via {Cooperative} {Coevolution}},
	volume = {23},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2018.2883599},
	abstract = {Engineering designs can involve multiple stages, where at each stage, the design models are incrementally modified and optimized. In contrast to traditional dynamic optimization problems, where the changes are caused by some objective factors, the changes in such incremental optimization problems (IOPs) are usually caused by the modifications made by the decision makers during the design process. While existing work in the literature is mainly focused on traditional dynamic optimization, little research has been dedicated to solving such IOPs. In this paper, we study how to adopt cooperative coevolution to efficiently solve a specific type of IOPs, namely, those with increasing decision variables. First, we present a benchmark function generator on the basis of some basic formulations of IOPs with increasing decision variables and exploitable modular structure. Then, we propose a contribution-based cooperative coevolutionary framework coupled with an incremental grouping method for dealing with them. On one hand, the benchmark function generator is capable of generating various benchmark functions with various characteristics. On the other hand, the proposed framework is promising in solving such problems in terms of both optimization accuracy and computational efficiency. In addition, the proposed method is further assessed using a real-world application, i.e., the design optimization of a stepped cantilever beam.},
	number = {5},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Cheng, Ran and Omidvar, Mohammad Nabi and Gandomi, Amir H. and Sendhoff, Bernhard and Menzel, Stefan and Yao, Xin},
	year = {2019},
	keywords = {Optimization, Benchmark testing, Computer science, Linear programming, Generators, Aerodynamics, Cooperative coevolution (CC), experience-based optimization, incremental optimization problem (IOP), Signal generators, variable grouping},
	pages = {762--775},
}

@article{cheng_evolutionary_2018,
	title = {Evolutionary {Multiobjective} {Optimization}-{Based} {Multimodal} {Optimization}: {Fitness} {Landscape} {Approximation} and {Peak} {Detection}},
	volume = {22},
	issn = {1941-0026},
	shorttitle = {Evolutionary {Multiobjective} {Optimization}-{Based} {Multimodal} {Optimization}},
	doi = {10.1109/TEVC.2017.2744328},
	abstract = {Recently, by taking advantage of evolutionary multiobjective optimization techniques in diversity preservation, the means of multiobjectivization has attracted increasing interest in the studies of multimodal optimization (MMO). While most existing work of multiobjectivization aims to find all optimal solutions simultaneously, in this paper, we propose to approximate multimodal fitness landscapes via multiobjectivization, thus providing an estimation of potential optimal areas. To begin with, an MMO problem is transformed into a multiobjective optimization problem (MOP) by adding an adaptive diversity indicator as the second optimization objective, and an approximate fitness landscape is obtained via optimization of the transformed MOP using a multiobjective evolutionary algorithm. Then, on the basis of the approximate fitness landscape, an adaptive peak detection method is proposed to find peaks where optimal solutions may exist. Finally, local search is performed inside the detected peaks on the approximate fitness landscape. To assess the performance of the proposed algorithm, extensive experiments are conducted on 20 multimodal test functions, in comparison with three state-of-the-art algorithms for MMO. Experimental results demonstrate that the proposed algorithm not only shows promising performance in benchmark comparisons, but also has good potential in assisting preference-based decision-making in MMO.},
	number = {5},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Cheng, Ran and Li, Miqing and Li, Ke and Yao, Xin},
	year = {2018},
	keywords = {Evolutionary computation, Optimization, Sociology, Statistics, Decision making, Approximation algorithms, Linear programming, multiobjective optimization, Decision-making, fitness landscape approximation, multimodal optimization (MMO), multiobjectivization, niching, peak detection, preference},
	pages = {692--706},
}

@article{gu_feature_2018,
	title = {Feature {Selection} for {High}-dimensional {Classification} {Using} a {Competitive} {Swarm} {Optimizer}},
	volume = {22},
	issn = {1433-7479},
	url = {https://doi.org/10.1007/s00500-016-2385-6},
	doi = {10.1007/s00500-016-2385-6},
	abstract = {When solving many machine learning problems such as classification, there exists a large number of input features. However, not all features are relevant for solving the problem, and sometimes, including irrelevant features may deteriorate the learning performance.Please check the edit made in the article title Therefore, it is essential to select the most relevant features, which is known as feature selection. Many feature selection algorithms have been developed, including evolutionary algorithms or particle swarm optimization (PSO) algorithms, to find a subset of the most important features for accomplishing a particular machine learning task. However, the traditional PSO does not perform well for large-scale optimization problems, which degrades the effectiveness of PSO for feature selection when the number of features dramatically increases. In this paper, we propose to use a very recent PSO variant, known as competitive swarm optimizer (CSO) that was dedicated to large-scale optimization, for solving high-dimensional feature selection problems. In addition, the CSO, which was originally developed for continuous optimization, is adapted to perform feature selection that can be considered as a combinatorial optimization problem. An archive technique is also introduced to reduce computational cost. Experiments on six benchmark datasets demonstrate that compared to the canonical PSO-based and a state-of-the-art PSO variant for feature selection, the proposed CSO-based feature selection algorithm not only selects a much smaller number of features, but result in better classification performance as well.},
	language = {en},
	number = {3},
	urldate = {2021-08-01},
	journal = {Soft Computing},
	author = {Gu, Shenkai and Cheng, Ran and Jin, Yaochu},
	year = {2018},
	pages = {811--822},
}

@article{zhang_decision_2018,
	title = {A {Decision} {Variable} {Clustering}-{Based} {Evolutionary} {Algorithm} for {Large}-{Scale} {Many}-{Objective} {Optimization}},
	volume = {22},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2016.2600642},
	abstract = {The current literature of evolutionary many-objective optimization is merely focused on the scalability to the number of objectives, while little work has considered the scalability to the number of decision variables. Nevertheless, many real-world problems can involve both many objectives and large-scale decision variables. To tackle such large-scale many-objective optimization problems (MaOPs), this paper proposes a specially tailored evolutionary algorithm based on a decision variable clustering method. To begin with, the decision variable clustering method divides the decision variables into two types: 1) convergence-related variables and 2) diversity-related variables. Afterward, to optimize the two types of decision variables, a convergence optimization strategy and a diversity optimization strategy are adopted. In addition, a fast nondominated sorting approach is developed to further improve the computational efficiency of the proposed algorithm. To assess the performance of the proposed algorithm, empirical experiments have been conducted on a variety of large-scale MaOPs with up to ten objectives and 5000 decision variables. Our experimental results demonstrate that the proposed algorithm has significant advantages over several state-of-the-art evolutionary algorithms in terms of the scalability to decision variables on MaOPs.},
	number = {1},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Zhang, Xingyi and Tian, Ye and Cheng, Ran and Jin, Yaochu},
	year = {2018},
	keywords = {Convergence, Evolutionary computation, Optimization, Computer science, Sorting, many-objective optimization, large-scale optimization, Clustering, Clustering methods, evolutionary multiobjective optimization, nondominated sorting, Scalability, tree},
	pages = {97--112},
}

@article{zhang_computational_2018,
	title = {Computational {Intelligence}-{Assisted} {Understanding} of {Nature}-{Inspired} {Superhydrophobic} {Behavior}},
	volume = {5},
	issn = {2198-3844},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.201700520},
	doi = {10.1002/advs.201700520},
	abstract = {In recent years, state-of-the-art computational modeling of physical and chemical systems has shown itself to be an invaluable resource in the prediction of the properties and behavior of functional materials. However, construction of a useful computational model for novel systems in both academic and industrial contexts often requires a great depth of physicochemical theory and/or a wealth of empirical data, and a shortage in the availability of either frustrates the modeling process. In this work, computational intelligence is instead used, including artificial neural networks and evolutionary computation, to enhance our understanding of nature-inspired superhydrophobic behavior. The relationships between experimental parameters (water droplet volume, weight percentage of nanoparticles used in the synthesis of the polymer composite, and distance separating the superhydrophobic surface and the pendant water droplet in adhesive force measurements) and multiple objectives (water droplet contact angle, sliding angle, and adhesive force) are built and weighted. The obtained optimal parameters are consistent with the experimental observations. This new approach to materials modeling has great potential to be applied more generally to aid design, fabrication, and optimization for myriad functional materials.},
	language = {en},
	number = {1},
	urldate = {2021-08-01},
	journal = {Advanced Science},
	author = {Zhang, Xia and Ding, Bei and Cheng, Ran and Dixon, Sebastian C. and Lu, Yao},
	year = {2018},
	keywords = {artificial neural networks, computational intelligence, evolutionary computation, superhydrophobic behavior},
	pages = {1700520},
}

@article{li_two-stage_2018,
	title = {A two-stage {R2} indicator {Based} {Evolutionary} {Algorithm} for {Many}-objective {Optimization}},
	volume = {67},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494618301078},
	doi = {10.1016/j.asoc.2018.02.048},
	abstract = {R2 indicator based multi-objective evolutionary algorithms (R2-MOEAs) have achieved promising performance on traditional multi-objective optimization problems (MOPs) with two and three objectives, but still cannot well handle many-objective optimization problems (MaOPs) with more than three objectives. To address this issue, this paper proposes a two-stage R2 indicator based evolutionary algorithm (TS-R2EA) for many-objective optimization. In the proposed TS-R2EA, we first adopt an R2 indicator based achievement scalarizing function for the primary selection. In addition, by taking advantage of the reference vector guided objective space partition approach in diversity management for many-objective optimization, the secondary selection strategy is further applied. Such a two-stage selection strategy is expected to achieve a balance between convergence and diversity. Extensive experiments are conducted on a variety of benchmark test problems, and the experimental results demonstrate that the proposed algorithm has competitive performance in comparison with several tailored algorithms for many-objective optimization.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Applied Soft Computing},
	author = {Li, Fei and Cheng, Ran and Liu, Jianchang and Jin, Yaochu},
	year = {2018},
	keywords = {Evolutionary algorithm, Many-objective optimization, R2 indicator, Reference vector, Two-stage selection strategy},
	pages = {245--260},
}

@article{zhang_competitive_2018,
	title = {A {Competitive} {Mechanism} {Based} {Multi}-objective {Particle} {Swarm} {Optimizer} with {Fast} {Convergence}},
	volume = {427},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025517310344},
	doi = {10.1016/j.ins.2017.10.037},
	abstract = {In the past two decades, multi-objective optimization has attracted increasing interests in the evolutionary computation community, and a variety of multi-objective optimization algorithms have been proposed on the basis of different population based meta-heuristics, where the family of multi-objective particle swarm optimization is among the most representative ones. While the performance of most existing multi-objective particle swarm optimization algorithms largely depends on the global or personal best particles stored in an external archive, in this paper, we propose a competitive mechanism based multi-objective particle swarm optimizer, where the particles are updated on the basis of the pairwise competitions performed in the current swarm at each generation. The performance of the proposed competitive multi-objective particle swarm optimizer is verified by benchmark comparisons with several state-of-the-art multi-objective optimizers, including three multi-objective particle swarm optimization algorithms and three multi-objective evolutionary algorithms. Experimental results demonstrate the promising performance of the proposed algorithm in terms of both optimization quality and convergence speed.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Information Sciences},
	author = {Zhang, Xingyi and Zheng, Xiutao and Cheng, Ran and Qiu, Jianfeng and Jin, Yaochu},
	year = {2018},
	keywords = {Particle swarm optimization, Evolutionary algorithm, Multi-objective optimization, Competitive swarm optimizer},
	pages = {63--76},
}

@article{cheng_model-based_2018,
	title = {Model-based {Evolutionary} {Algorithms}: a {Short} {Survey}},
	volume = {4},
	issn = {2198-6053},
	shorttitle = {Model-based evolutionary algorithms},
	url = {https://doi.org/10.1007/s40747-018-0080-1},
	doi = {10.1007/s40747-018-0080-1},
	abstract = {The evolutionary algorithms (EAs) are a family of nature-inspired algorithms widely used for solving complex optimization problems. Since the operators (e.g. crossover, mutation, selection) in most traditional EAs are developed on the basis of fixed heuristic rules or strategies, they are unable to learn the structures or properties of the problems to be optimized. To equip the EAs with learning abilities, recently, various model-based evolutionary algorithms (MBEAs) have been proposed. This survey briefly reviews some representative MBEAs by considering three different motivations of using models. First, the most commonly seen motivation of using models is to estimate the distribution of the candidate solutions. Second, in evolutionary multi-objective optimization, one motivation of using models is to build the inverse models from the objective space to the decision space. Third, when solving computationally expensive problems, models can be used as surrogates of the fitness functions. Based on the review, some further discussions are also given.},
	language = {en},
	number = {4},
	urldate = {2021-08-01},
	journal = {Complex \& Intelligent Systems},
	author = {Cheng, Ran and He, Cheng and Jin, Yaochu and Yao, Xin},
	year = {2018},
	pages = {283--292},
}

@article{tian_strengthened_2019,
	title = {A {Strengthened} {Dominance} {Relation} {Considering} {Convergence} and {Diversity} for {Evolutionary} {Many}-{Objective} {Optimization}},
	volume = {23},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2018.2866854},
	abstract = {Both convergence and diversity are crucial to evolutionary many-objective optimization, whereas most existing dominance relations show poor performance in balancing them, thus easily leading to a set of solutions concentrating on a small region of the Pareto fronts. In this paper, a novel dominance relation is proposed to better balance convergence and diversity for evolutionary many-objective optimization. In the proposed dominance relation, an adaptive niching technique is developed based on the angles between the candidate solutions, where only the best converged candidate solution is identified to be nondominated in each niche. Experimental results demonstrate that the proposed dominance relation outperforms existing dominance relations in balancing convergence and diversity. A modified NSGA-II is suggested based on the proposed dominance relation, which shows competitiveness against the state-of-the-art algorithms in solving many-objective optimization problems. The effectiveness of the proposed dominance relation is also verified on several other existing multi- and many-objective evolutionary algorithms.},
	number = {2},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Tian, Ye and Cheng, Ran and Zhang, Xingyi and Su, Yansen and Jin, Yaochu},
	year = {2019},
	keywords = {Convergence, Evolutionary computation, Pareto optimization, many-objective optimization, evolutionary algorithm, diversity, Genetic algorithms, Pareto dominance},
	pages = {331--345},
}

@article{tian_platemo_2017,
	title = {{PlatEMO}: {A} {MATLAB} {Platform} for {Evolutionary} {Multi}-{Objective} {Optimization} [{Educational} {Forum}]},
	volume = {12},
	issn = {1556-6048},
	shorttitle = {{PlatEMO}},
	doi = {10.1109/MCI.2017.2742868},
	abstract = {Over the last three decades, a large number of evolutionary algorithms have been developed for solving multi-objective optimization problems. However, there lacks an upto-date and comprehensive software platform for researchers to properly benchmark existing algorithms and for practitioners to apply selected algorithms to solve their real-world problems. The demand of such a common tool becomes even more urgent, when the source code of many proposed algorithms has not been made publicly available. To address these issues, we have developed a MATLAB platform for evolutionary multi-objective optimization in this paper, called PlatEMO, which includes more than 50 multiobjective evolutionary algorithms and more than 100 multi-objective test problems, along with several widely used performance indicators. With a user-friendly graphical user interface, PlatEMO enables users to easily compare several evolutionary algorithms at one time and collect statistical results in Excel or LaTeX files. More importantly, PlatEMO is completely open source, such that users are able to develop new algorithms on the basis of it. This paper introduces the main features of PlatEMO and illustrates how to use it for performing comparative experiments, embedding new algorithms, creating new test problems, and developing performance indicators. Source code of PlatEMO is now available at: http://bimk.ahu.edu.cn/index.php?s=/Index/Software/index.html.},
	number = {4},
	journal = {IEEE Computational Intelligence Magazine},
	author = {Tian, Ye and Cheng, Ran and Zhang, Xingyi and Jin, Yaochu},
	year = {2017},
	keywords = {Evolutionary computation, Optimization, Sorting, Genetic algorithms, Algorithm design and analysis, MATLAB},
	pages = {73--87},
}

@article{cheng_evolutionary_2017,
	title = {Evolutionary {Many}-{Objective} {Optimization} of {Hybrid} {Electric} {Vehicle} {Control}: {From} {General} {Optimization} to {Preference} {Articulation}},
	volume = {1},
	issn = {2471-285X},
	shorttitle = {Evolutionary {Many}-{Objective} {Optimization} of {Hybrid} {Electric} {Vehicle} {Control}},
	doi = {10.1109/TETCI.2017.2669104},
	abstract = {Many real-world optimization problems have more than three objectives, which has triggered increasing research interest in developing efficient and effective evolutionary algorithms for solving many-objective optimization problems. However, most many-objective evolutionary algorithms have only been evaluated on benchmark test functions and few applied to real-world optimization problems. To move a step forward, this paper presents a case study of solving a many-objective hybrid electric vehicle controller design problem using three state-of-the-art algorithms, namely, a decomposition based evolutionary algorithm (MOEA/D), a non-dominated sorting based genetic algorithm (NSGA-III), and a reference vector guided evolutionary algorithm (RVEA). We start with atypical setting aimed at approximating the Pareto front without introducing any user preferences. Based on the analyses of the approximated Pareto front, we introduce a preference articulation method and embed it in the three evolutionary algorithms for identifying solutions that the decision-maker prefers. Our experimental results demonstrate that by incorporating user preferences into many-objective evolutionary algorithms, we are not only able to gain deep insight into the trade-off relationships between the objectives, but also to achieve high-quality solutions reflecting the decision-maker's preferences. In addition, our experimental results indicate that each of the three algorithms examined in this work has its unique advantages that can be exploited when applied to the optimization of real-world problems.},
	number = {2},
	journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	author = {Cheng, Ran and Rodemann, Tobias and Fischer, Michael and Olhofer, Markus and Jin, Yaochu},
	year = {2017},
	keywords = {Convergence, Evolutionary computation, Optimization, Sorting, many-objective optimization, Evolutionary algorithm, Algorithm design and analysis, hybrid electric vehicle, Hybrid electric vehicles, preference articulation, reference vector},
	pages = {97--111},
}

@article{sun_surrogate-assisted_2017,
	title = {Surrogate-{Assisted} {Cooperative} {Swarm} {Optimization} of {High}-{Dimensional} {Expensive} {Problems}},
	volume = {21},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2017.2675628},
	abstract = {Surrogate models have shown to be effective in assisting metaheuristic algorithms for solving computationally expensive complex optimization problems. The effectiveness of existing surrogate-assisted metaheuristic algorithms, however, has only been verified on low-dimensional optimization problems. In this paper, a surrogate-assisted cooperative swarm optimization algorithm is proposed, in which a surrogate-assisted particle swarm optimization (PSO) algorithm and a surrogate-assisted social learning-based PSO (SL-PSO) algorithm cooperatively search for the global optimum. The cooperation between the PSO and the SL-PSO consists of two aspects. First, they share promising solutions evaluated by the real fitness function. Second, the SL-PSO focuses on exploration while the PSO concentrates on local search. Empirical studies on six 50-D and six 100-D benchmark problems demonstrate that the proposed algorithm is able to find high-quality solutions for high-dimensional problems on a limited computational budget.},
	number = {4},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Sun, Chaoli and Jin, Yaochu and Cheng, Ran and Ding, Jinliang and Zeng, Jianchao},
	year = {2017},
	keywords = {Convergence, Optimization, Search problems, Particle swarm optimization, Computational modeling, Estimation, Algorithm design and analysis, Computationally expensive problems, fitness estimation strategy (FES), particle swarm optimization (PSO), radial-basis-function networks, surrogate models},
	pages = {644--660},
}

@article{cheng_benchmark_2017,
	title = {A {Benchmark} {Test} {Suite} for {Evolutionary} {Many}-objective {Optimization}},
	url = {https://dora.dmu.ac.uk/handle/2086/13841},
	doi = {10.1007/s40747-017-0039-7},
	abstract = {In the real world, it is not uncommon to face an optimization problem with more than three objectives. Such problems, called many-objective optimization problems (MaOPs), pose great challenges to the area of evolutionary computation. The failure of conventional Pareto-based multi-objective evolutionary algorithms in dealing with MaOPs motivates various new approaches. However, in contrast to the rapid development of algorithm design, performance investigation and comparison of algorithms have received little attention. Several test problem suites which were designed for multi-objective optimization have still been dominantly used in many-objective optimization. In this paper, we carefully select (or modify) 15 test problems with diverse properties to construct a benchmark test suite, aiming to promote the research of evolutionary many-objective optimization (EMaO) via suggesting a set of test problems with a good representation of various real-world scenarios. Also, an open-source software platform with a user-friendly GUI is provided to facilitate the experimental execution and data observation.},
	language = {en\_US},
	urldate = {2021-08-01},
	author = {Cheng, Ran and Li, Miqing and Tian, Ye and Zhang, Xingyi and Yang, Shengxiang and Jin, Yaochu and Yao, Xin},
	year = {2017},
}

@article{tian_indicator-based_2018,
	title = {An {Indicator}-{Based} {Multiobjective} {Evolutionary} {Algorithm} {With} {Reference} {Point} {Adaptation} for {Better} {Versatility}},
	volume = {22},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2017.2749619},
	abstract = {During the past two decades, a variety of multiobjective evolutionary algorithms (MOEAs) have been proposed in the literature. As pointed out in some recent studies, however, the performance of an MOEA can strongly depend on the Pareto front shape of the problem to be solved, whereas most existing MOEAs show poor versatility on problems with different shapes of Pareto fronts. To address this issue, we propose an MOEA based on an enhanced inverted generational distance indicator, in which an adaptation method is suggested to adjust a set of reference points based on the indicator contributions of candidate solutions in an external archive. Our experimental results demonstrate that the proposed algorithm is versatile for solving problems with various types of Pareto fronts, outperforming several state-of-the-art evolutionary algorithms for multiobjective and many-objective optimization.},
	number = {4},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Tian, Ye and Cheng, Ran and Zhang, Xingyi and Cheng, Fan and Jin, Yaochu},
	year = {2018},
	keywords = {Evolutionary computation, Optimization, Sociology, Statistics, Electronic mail, Computer science, many-objective optimization, Shape, evolutionary multiobjective optimization, Adaptive reference point, indicator-based selection},
	pages = {609--622},
}

@article{cheng_test_2017,
	title = {Test {Problems} for {Large}-{Scale} {Multiobjective} and {Many}-{Objective} {Optimization}},
	volume = {47},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2016.2600577},
	abstract = {The interests in multiobjective and many-objective optimization have been rapidly increasing in the evolutionary computation community. However, most studies on multiobjective and many-objective optimization are limited to small-scale problems, despite the fact that many real-world multiobjective and many-objective optimization problems may involve a large number of decision variables. As has been evident in the history of evolutionary optimization, the development of evolutionary algorithms (EAs) for solving a particular type of optimization problems has undergone a co-evolution with the development of test problems. To promote the research on large-scale multiobjective and many-objective optimization, we propose a set of generic test problems based on design principles widely used in the literature of multiobjective and many-objective optimization. In order for the test problems to be able to reflect challenges in real-world applications, we consider mixed separability between decision variables and nonuniform correlation between decision variables and objective functions. To assess the proposed test problems, six representative evolutionary multiobjective and many-objective EAs are tested on the proposed test problems. Our empirical results indicate that although the compared algorithms exhibit slightly different capabilities in dealing with the challenges in the test problems, none of them are able to efficiently solve these optimization problems, calling for the need for developing new EAs dedicated to large-scale multiobjective and many-objective optimization.},
	number = {12},
	journal = {IEEE Transactions on Cybernetics},
	author = {Cheng, Ran and Jin, Yaochu and Olhofer, Markus and sendhoff, Bernhard},
	year = {2017},
	keywords = {Evolutionary computation, Benchmark testing, Pareto optimization, many-objective optimization, Linear programming, large-scale optimization, multiobjective optimization, Evolutionary algorithms (EAs), test problems, Testing},
	pages = {4108--4121},
}

@article{cheng_reference_2016,
	title = {A {Reference} {Vector} {Guided} {Evolutionary} {Algorithm} for {Many}-{Objective} {Optimization}},
	volume = {20},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2016.2519378},
	abstract = {In evolutionary multiobjective optimization, maintaining a good balance between convergence and diversity is particularly crucial to the performance of the evolutionary algorithms (EAs). In addition, it becomes increasingly important to incorporate user preferences because it will be less likely to achieve a representative subset of the Pareto-optimal solutions using a limited population size as the number of objectives increases. This paper proposes a reference vector-guided EA for many-objective optimization. The reference vectors can be used not only to decompose the original multiobjective optimization problem into a number of single-objective subproblems, but also to elucidate user preferences to target a preferred subset of the whole Pareto front (PF). In the proposed algorithm, a scalarization approach, termed angle-penalized distance, is adopted to balance convergence and diversity of the solutions in the high-dimensional objective space. An adaptation strategy is proposed to dynamically adjust the distribution of the reference vectors according to the scales of the objective functions. Our experimental results on a variety of benchmark test problems show that the proposed algorithm is highly competitive in comparison with five state-of-the-art EAs for many-objective optimization. In addition, we show that reference vectors are effective and cost-efficient for preference articulation, which is particularly desirable for many-objective optimization. Furthermore, a reference vector regeneration strategy is proposed for handling irregular PFs. Finally, the proposed algorithm is extended for solving constrained many-objective optimization problems.},
	number = {5},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Cheng, Ran and Jin, Yaochu and Olhofer, Markus and Sendhoff, Bernhard},
	year = {2016},
	keywords = {Convergence, Evolutionary computation, Sociology, Pareto optimization, many-objective optimization, Linear programming, evolutionary multiobjective optimization, diversity, preference articulation, reference vector, Angle-penalized distance (APD), convergence},
	pages = {773--791},
}

@article{cheng_multiobjective_2015,
	title = {A {Multiobjective} {Evolutionary} {Algorithm} {Using} {Gaussian} {Process}-{Based} {Inverse} {Modeling}},
	volume = {19},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2015.2395073},
	abstract = {To approximate the Pareto front, most existing multiobjective evolutionary algorithms store the nondominated solutions found so far in the population or in an external archive during the search. Such algorithms often require a high degree of diversity of the stored solutions and only a limited number of solutions can be achieved. By contrast, model-based algorithms can alleviate the requirement on solution diversity and in principle, as many solutions as needed can be generated. This paper proposes a new model-based method for representing and searching nondominated solutions. The main idea is to construct Gaussian process-based inverse models that map all found nondominated solutions from the objective space to the decision space. These inverse models are then used to create offspring by sampling the objective space. To facilitate inverse modeling, the multivariate inverse function is decomposed into a group of univariate functions, where the number of inverse models is reduced using a random grouping technique. Extensive empirical simulations demonstrate that the proposed algorithm exhibits robust search performance on a variety of medium to high dimensional multiobjective optimization test problems. Additional nondominated solutions are generated a posteriori using the constructed models to increase the density of solutions in the preferred regions at a low computational cost.},
	number = {6},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Cheng, Ran and Jin, Yaochu and Narukawa, Kaname and Sendhoff, Bernhard},
	year = {2015},
	keywords = {Sociology, Vectors, Multiobjective optimization, Pareto optimization, Gaussian processes, estimation of distribution algorithms, Estimation of distribution algorithms (EDAs), Gaussian processes (GPs), inverse modeling, Inverse problems, multiobjective optimization (MOO), random grouping},
	pages = {838--856},
}

@article{cheng_competitive_2015,
	title = {A {Competitive} {Swarm} {Optimizer} for {Large} {Scale} {Optimization}},
	volume = {45},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2014.2322602},
	abstract = {In this paper, a novel competitive swarm optimizer (CSO) for large scale optimization is proposed. The algorithm is fundamentally inspired by the particle swarm optimization but is conceptually very different. In the proposed CSO, neither the personal best position of each particle nor the global best position (or neighborhood best positions) is involved in updating the particles. Instead, a pairwise competition mechanism is introduced, where the particle that loses the competition will update its position by learning from the winner. To understand the search behavior of the proposed CSO, a theoretical proof of convergence is provided, together with empirical analysis of its exploration and exploitation abilities showing that the proposed CSO achieves a good balance between exploration and exploitation. Despite its algorithmic simplicity, our empirical results demonstrate that the proposed CSO exhibits a better overall performance than five state-of-the-art metaheuristic algorithms on a set of widely used large scale optimization problems and is able to effectively solve problems of dimensionality up to 5000.},
	number = {2},
	journal = {IEEE Transactions on Cybernetics},
	author = {Cheng, Ran and Jin, Yaochu},
	year = {2015},
	keywords = {Convergence, Optimization, Vectors, Particle swarm optimization, Heuristic algorithms, Algorithm design and analysis, Competition, competitive swarm optimizer, convergence analysis, Cybernetics, large scale optimization, learning, particle swarm optimization},
	pages = {191--204},
}

@article{cheng_social_2015,
	title = {A {Social} {Learning} {Particle} {Swarm} {Optimization} {Algorithm} for {Scalable} {Optimization}},
	volume = {291},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025514008366},
	doi = {10.1016/j.ins.2014.08.039},
	abstract = {Social learning plays an important role in behavior learning among social animals. In contrast to individual (asocial) learning, social learning has the advantage of allowing individuals to learn behaviors from others without incurring the costs of individual trials-and-errors. This paper introduces social learning mechanisms into particle swarm optimization (PSO) to develop a social learning PSO (SL-PSO). Unlike classical PSO variants where the particles are updated based on historical information, including the best solution found by the whole swarm (global best) and the best solution found by each particle (personal best), each particle in the proposed SL-PSO learns from any better particles (termed demonstrators) in the current swarm. In addition, to ease the burden of parameter settings, the proposed SL-PSO adopts a dimension-dependent parameter control method. The proposed SL-PSO is first compared with five representative PSO variants on 40 low-dimensional test functions, including shifted and rotated test functions. The scalability of the proposed SL-PSO is further tested by comparing it with five state-of-the-art algorithms for large-scale optimization on seven high-dimensional (100-D, 500-D, and 1000-D) benchmark functions. Our comparative results show that SL-PSO performs well on low-dimensional problems and is promising for solving large-scale problems as well.},
	language = {en},
	urldate = {2021-08-01},
	journal = {Information Sciences},
	author = {Cheng, Ran and Jin, Yaochu},
	year = {2015},
	keywords = {Particle swarm optimization, Large-scale optimization, Scalability, Computational efficiency, Social learning},
	pages = {43--60},
}

@article{zhang_efficient_2015,
	title = {An {Efficient} {Approach} to {Nondominated} {Sorting} for {Evolutionary} {Multiobjective} {Optimization}},
	volume = {19},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2014.2308305},
	abstract = {Evolutionary algorithms have been shown to be powerful for solving multiobjective optimization problems, in which nondominated sorting is a widely adopted technique in selection. This technique, however, can be computationally expensive, especially when the number of individuals in the population becomes large. This is mainly because in most existing nondominated sorting algorithms, a solution needs to be compared with all other solutions before it can be assigned to a front. In this paper we propose a novel, computationally efficient approach to nondominated sorting, termed efficient nondominated sort (ENS). In ENS, a solution to be assigned to a front needs to be compared only with those that have already been assigned to a front, thereby avoiding many unnecessary dominance comparisons. Based on this new approach, two nondominated sorting algorithms have been suggested. Both theoretical analysis and empirical results show that the ENS-based sorting algorithms are computationally more efficient than the state-of-the-art nondominated sorting methods.},
	number = {2},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Zhang, Xingyi and Tian, Ye and Cheng, Ran and Jin, Yaochu},
	year = {2015},
	keywords = {Optimization, Sociology, Statistics, Sorting, Time complexity, evolutionary multiobjective optimization, nondominated sorting, Algorithm design and analysis, Computational complexity, Pareto-optimality},
	pages = {201--213},
}

@article{gu_multi-objective_2015,
	title = {Multi-objective {Ensemble} {Generation}},
	volume = {5},
	issn = {1942-4795},
	url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1158},
	doi = {10.1002/widm.1158},
	abstract = {Ensemble methods that combine a committee of machine-learning models, each known as a member or base learner, have gained research interests in the past decade. One interest on ensemble generation involves the multi-objective approach, which attempts to generate both accurate and diverse members that fulfill the theoretical requirements of good ensembles. These methods resolve common difficulties of balancing the trade-off between accuracy and diversity and have been shown to be advantageous over single-objective methods. This study presents an up-to-date survey on multi-objective ensemble generation methods, including widely used diversity measures, member generation, selection, and integration techniques. Challenges and potential applications of multi-objective ensemble generation are also discussed. WIREs Data Mining Knowl Discov 2015, 5:234‚Äì245. doi: 10.1002/widm.1158 This article is categorized under: Algorithmic Development {\textbackslash}textgreater Ensemble Methods},
	language = {en},
	number = {5},
	urldate = {2021-08-01},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Gu, Shenkai and Cheng, Ran and Jin, Yaochu},
	year = {2015},
	pages = {234--245},
}

@article{tian_guiding_2020,
	title = {Guiding {Evolutionary} {Multiobjective} {Optimization} {With} {Generic} {Front} {Modeling}},
	volume = {50},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2018.2883914},
	abstract = {In evolutionary multiobjective optimization, the Pareto front (PF) is approximated by using a set of representative candidate solutions with good convergence and diversity. However, most existing multiobjective evolutionary algorithms (MOEAs) have general difficulty in the approximation of PFs with complicated geometries. To address this issue, we propose a generic front modeling method for evolutionary multiobjective optimization, where the shape of the nondominated front is estimated by training a generalized simplex model. On the basis of the estimated front, we further develop an MOEA, where both the mating selection and environmental selection are driven by the approximate nondominated fronts modeled during the optimization process. For performance assessment, the proposed algorithm is compared with several state-of-the-art evolutionary algorithms on a wide range of benchmark problems with various types of PFs and different numbers of objectives. Experimental results demonstrate that the proposed algorithm performs consistently on a variety of multiobjective optimization problems.},
	number = {3},
	journal = {IEEE Transactions on Cybernetics},
	author = {Tian, Ye and Zhang, Xingyi and Cheng, Ran and He, Cheng and Jin, Yaochu},
	year = {2020},
	keywords = {Evolutionary computation, Optimization, Sociology, Statistics, Computer science, Evolutionary algorithm, Shape, Training, fitness function, front modeling, multiobjective and many-objective optimization},
	pages = {1106--1119},
}

@article{he_evolutionary_2021,
	title = {Evolutionary {Multiobjective} {Optimization} {Driven} by {Generative} {Adversarial} {Networks} ({GANs})},
	volume = {51},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2020.2985081},
	abstract = {Recently, increasing works have been proposed to drive evolutionary algorithms using machine-learning models. Usually, the performance of such model-based evolutionary algorithms is highly dependent on the training qualities of the adopted models. Since it usually requires a certain amount of data (i.e., the candidate solutions generated by the algorithms) for model training, the performance deteriorates rapidly with the increase of the problem scales due to the curse of dimensionality. To address this issue, we propose a multiobjective evolutionary algorithm driven by the generative adversarial networks (GANs). At each generation of the proposed algorithm, the parent solutions are first classified into real and fake samples to train the GANs; then the offspring solutions are sampled by the trained GANs. Thanks to the powerful generative ability of the GANs, our proposed algorithm is capable of generating promising offspring solutions in high-dimensional decision space with limited training data. The proposed algorithm is tested on ten benchmark problems with up to 200 decision variables. The experimental results on these test problems demonstrate the effectiveness of the proposed algorithm.},
	number = {6},
	journal = {IEEE Transactions on Cybernetics},
	author = {He, Cheng and Huang, Shihua and Cheng, Ran and Tan, Kay Chen and Jin, Yaochu},
	year = {2021},
	keywords = {Evolutionary computation, Optimization, Training data, Computational modeling, multiobjective optimization, Deep learning, evolutionary algorithm, Machine learning, Adaptation models, Generative adversarial networks, generative adversarial networks (GANs), machine learning},
	pages = {3129--3142},
}

@inproceedings{cheng_visualization_2017,
	title = {A {Visualization} {Method} for {Benchmark} {Studies} of {Multimodal} {Optimization}},
	author = {Cheng, Ran and Li, Miqing and Yao, Xin},
	year = {2017},
}

@article{yazdani_survey_2021-1,
	title = {A {Survey} of {Evolutionary} {Continuous} {Dynamic} {Optimization} {Over} {Two} {Decades}‚Äî{Part} {A}},
	volume = {25},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2021.3060014},
	abstract = {Many real-world optimization problems are dynamic. The field of dynamic optimization deals with such problems where the search space changes over time. In this two-part article, we present a comprehensive survey of the research in evolutionary dynamic optimization for single-objective unconstrained continuous problems over the last two decades. In Part A of this survey, we propose a new taxonomy for the components of dynamic optimization algorithms (DOAs), namely, convergence detection, change detection, explicit archiving, diversity control, and population division and management. In comparison to the existing taxonomies, the proposed taxonomy covers some additional important components, such as convergence detection and computational resource allocation. Moreover, we significantly expand and improve the classifications of diversity control and multipopulation methods, which are underrepresented in the existing taxonomies. We then provide detailed technical descriptions and analysis of different components according to the suggested taxonomy. Part B of this survey provides an in-depth analysis of the most commonly used benchmark problems, performance analysis methods, static optimization algorithms used as the optimization components in the DOAs, and dynamic real-world applications. Finally, several opportunities for future work are pointed out.},
	number = {4},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Yazdani, Danial and Cheng, Ran and Yazdani, Donya and Branke, J√ºrgen and Jin, Yaochu and Yao, Xin},
	month = aug,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Evolutionary Computation},
	keywords = {Search problems, Sociology, Benchmark testing, Heuristic algorithms, unconstrained continuous dynamic optimization, multipopulation, Resource management, Change detection, Classification algorithms, evolutionary algorithms (EA), response component, taxonomy, Taxonomy},
	pages = {609--629},
	file = {IEEE Xplore Abstract Record:files/234/9356715.html:text/html},
}

@article{tan_relativenas_2021,
	title = {{RelativeNAS}: {Relative} {Neural} {Architecture} {Search} via {Slow}-{Fast} {Learning}},
	issn = {2162-2388},
	shorttitle = {{RelativeNAS}},
	doi = {10.1109/TNNLS.2021.3096658},
	abstract = {Despite the remarkable successes of convolutional neural networks (CNNs) in computer vision, it is time-consuming and error-prone to manually design a CNN. Among various neural architecture search (NAS) methods that are motivated to automate designs of high-performance CNNs, the differentiable NAS and population-based NAS are attracting increasing interests due to their unique characters. To benefit from the merits while overcoming the deficiencies of both, this work proposes a novel NAS method, RelativeNAS. As the key to efficient search, RelativeNAS performs joint learning between fast learners (i.e., decoded networks with relatively lower loss value) and slow learners in a pairwise manner. Moreover, since RelativeNAS only requires low-fidelity performance estimation to distinguish each pair of fast learner and slow learner, it saves certain computation costs for training the candidate architectures. The proposed RelativeNAS brings several unique advantages: 1) it achieves state-of-the-art performances on ImageNet with top-1 error rate of 24.88\%, that is, outperforming DARTS and AmoebaNet-B by 1.82\% and 1.12\%, respectively; 2) it spends only 9 h with a single 1080Ti GPU to obtain the discovered cells, that is, 3.75x and 7875x faster than DARTS and AmoebaNet, respectively; and 3) it provides that the discovered cells obtained on CIFAR-10 can be directly transferred to object detection, semantic segmentation, and keypoint detection, yielding competitive results of 73.1\% mAP on PASCAL VOC, 78.7\% mIoU on Cityscapes, and 68.5\% AP on MSCOCO, respectively. The implementation of RelativeNAS is available at https://github.com/EMI-Group/RelativeNAS.},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Tan, Hao and Cheng, Ran and Huang, Shihua and He, Cheng and Qiu, Changxiao and Yang, Fan and Luo, Ping},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Optimization, Search problems, Sociology, Statistics, AutoML, Computer architecture, convolutional neural network (CNN), Estimation, neural architecture search (NAS), Neural networks, population-based search, slow-fast learning.},
	pages = {1--15},
	file = {IEEE Xplore Abstract Record:files/246/9488309.html:text/html},
}

@inproceedings{li_large-scale_2021,
	title = {Large-scale {Multiobjective} {Optimization} via {Problem} {Decomposition} and {Reformulation}},
	doi = {10.1109/CEC45853.2021.9504820},
	abstract = {Large-scale multiobjective optimization problems (LSMOPs) are challenging for existing approaches due to the complexity of objective functions and the massive volume of decision space. Some large-scale multiobjective evolutionary algorithms (LSMOEAs) have recently been proposed, which have shown their effectiveness in solving some benchmarks and real-world applications. They merely focus on handling the massive volume of decision space and ignore the complexity of LSMOPs in terms of objective functions. The complexity issue is also important since the complexity grows along with the increment in the number of decision variables. Our previous study proposed a framework to accelerate evolutionary large-scale multiobjective optimization via problem reformulation for handling large-scale decision variables. Here, we investigate the effectiveness of LSMOF combined with decomposition-based MOEA (MOEA/D), aiming to handle the complexity of LSMOPs in both the decision and objective spaces. Specifically, MOEA/D is embedded in LSMOF via two different strategies, and the proposed algorithm is tested on various benchmark LSMOPs. Experimental results indicate the encouraging performance improvement benefited from the solution of the complexity issue in large-scale multiobjective optimization.},
	booktitle = {2021 {IEEE} {Congress} on {Evolutionary} {Computation} ({CEC})},
	author = {Li, Lianghao and He, Cheng and Cheng, Ran and Pan, Linqiang},
	month = jun,
	year = {2021},
	keywords = {Evolutionary computation, Optimization, Sociology, Statistics, Multiobjective optimization, Benchmark testing, Linear programming, large-scale optimization, problem reformulation, Complexity theory, offspring generation, problem decomposition},
	pages = {2149--2155},
	file = {IEEE Xplore Abstract Record:files/250/9504820.html:text/html},
}

@article{he_efficient_2021,
	title = {Efficient {Evolutionary} {Neural} {Architecture} {Search} by {Modular} {Inheritable} {Crossover}},
	volume = {64},
	issn = {2210-6502},
	url = {https://www.sciencedirect.com/science/article/pii/S2210650221000559},
	doi = {10.1016/j.swevo.2021.100894},
	abstract = {Deep neural networks are widely used in the domain of image classification, and a large number of excellent deep neural networks have been proposed in recent years. However, hand-crafted neural networks often require human experts for elaborate designs, which can be time-consuming and error-prone. Hence, neural architecture search (NAS) methods have been proposed to design model architecture automatically. The evolutionary NAS methods have achieved encouraging results due to the global search capability of evolutionary algorithms. Nevertheless, most existing evolutionary NAS methods use only the mutation operator to generate offspring architectures. Consequently, the generated architectures could be pretty different from their parent architectures, failing to inherit the modular information to accelerate the convergence rate. We propose an efficient evolutionary method using a tailored crossover operator to address this deficiency, which enables the offspring architectures to inherit from their parent architectures. Moreover, we combine it with mutation operators under the framework of the evolutionary algorithm. Experimental results on both the CIFAR-10 and CIFAR-100 tasks show that our proposed evolutionary NAS method has achieved state-of-the-art results.},
	language = {en},
	urldate = {2021-08-26},
	journal = {Swarm and Evolutionary Computation},
	author = {He, Cheng and Tan, Hao and Huang, Shihua and Cheng, Ran},
	month = jul,
	year = {2021},
	keywords = {Evolutionary algorithm, Image classification, Inheritable crossover, Neural architecture search},
	pages = {100894},
	file = {ScienceDirect Snapshot:files/255/S2210650221000559.html:text/html},
}

@inproceedings{chen_efficient_2020,
	address = {Singapore},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Efficient {Evolutionary} {Deep} {Neural} {Architecture} {Search} ({NAS}) by {Noisy} {Network} {Morphism} {Mutation}},
	isbn = {9789811534157},
	doi = {10.1007/978-981-15-3415-7_41},
	abstract = {Deep learning has achieved enormous breakthroughs in the field of image recognition. However, due to the time-consuming and error-prone process in discovering novel neural architecture, it remains a challenge for designing a specific network in handling a particular task. Hence, many automated neural architecture search methods are proposed to find suitable deep neural network architecture for a specific task without human experts. Nevertheless, these methods are still computationally/economically expensive, since they require a vast amount of computing resource and/or computational time. In this paper, we propose several network morphism mutation operators with extra noise, and further redesign the macro-architecture based on the classical network. The proposed methods are embedded in an evolutionary algorithm and tested on CIFAR-10 classification task. Experimental results indicate the capability of our proposed method in discovering powerful neural architecture which has achieved a classification error 2.55\% with only 4.7M parameters on CIFAR-10 within 12 GPU-hours.},
	language = {en},
	booktitle = {Bio-inspired {Computing}: {Theories} and {Applications}},
	publisher = {Springer},
	author = {Chen, Yiming and Pan, Tianci and He, Cheng and Cheng, Ran},
	editor = {Pan, Linqiang and Liang, Jing and Qu, Boyang},
	year = {2020},
	keywords = {Evolutionary algorithm, Neural architecture search, Network morphism},
	pages = {497--508},
}

@article{kong_constructing_2020,
	title = {Constructing an {Automatic} {Diagnosis} and {Severity}-classification {Model} for {Acromegaly} using {Facial} {Photographs} by {Deep} {Learning}},
	volume = {13},
	issn = {1756-8722},
	url = {https://doi.org/10.1186/s13045-020-00925-y},
	doi = {10.1186/s13045-020-00925-y},
	abstract = {Due to acromegaly‚Äôs insidious onset and slow progression, its diagnosis is usually delayed, thus causing severe complications and treatment difficulty. A convenient screening method is imperative. Based on our previous work, we herein developed a new automatic diagnosis and severity-classification model for acromegaly using facial photographs by deep learning on the data of 2148 photographs at different severity levels. Each photograph was given a score reflecting its severity (range 1{\textasciitilde}3). Our developed model achieved a prediction accuracy of 90.7\% on the internal test dataset and outperformed the performance of ten junior internal medicine physicians (89.0\%). The prospect of applying this model to real clinical practices is promising due to its potential health economic benefits.},
	number = {1},
	urldate = {2021-08-26},
	journal = {Journal of Hematology \& Oncology},
	author = {Kong, Yanguo and Kong, Xiangyi and He, Cheng and Liu, Changsong and Wang, Liting and Su, Lijuan and Gao, Jun and Guo, Qi and Cheng, Ran},
	month = jul,
	year = {2020},
	keywords = {Deep learning, Acromegaly, Facial photographs, Severity-classification model},
	pages = {88},
	file = {Full Text PDF:files/260/Kong Á≠â„ÄÇ - 2020 - Constructing an automatic diagnosis and severity-c.pdf:application/pdf;Snapshot:files/261/s13045-020-00925-y.html:text/html},
}

@article{lin_adaptive_2021,
	title = {Adaptive {Dropout} for {High}-dimensional {Expensive} {Multiobjective} {Optimization}},
	issn = {2198-6053},
	url = {https://doi.org/10.1007/s40747-021-00362-5},
	doi = {10.1007/s40747-021-00362-5},
	abstract = {Various works have been proposed to solve expensive multiobjective optimization problems (EMOPs) using surrogate-assisted evolutionary algorithms (SAEAs) in recent decades. However, most existing methods focus on EMOPs with less than 30 decision variables, since a large number of training samples are required to build an accurate surrogate model for high-dimensional EMOPs, which is unrealistic for expensive multiobjective optimization. To address this issue, we propose an SAEA with an adaptive dropout mechanism. Specifically, this mechanism takes advantage of the statistical differences between different solution sets in the decision space to guide the selection of some crucial decision variables. A new infill criterion is then proposed to optimize the selected decision variables with the assistance of surrogate models. Moreover, the optimized decision variables are extended to new full-length solutions, and then the new candidate solutions are evaluated using expensive functions to update the archive. The proposed algorithm is tested on different benchmark problems with up to 200 decision variables compared to some state-of-the-art SAEAs. The experimental results have demonstrated the promising performance and computational efficiency of the proposed algorithm in high-dimensional expensive multiobjective optimization.},
	language = {en},
	urldate = {2021-08-26},
	journal = {Complex \& Intelligent Systems},
	author = {Lin, Jianqing and He, Cheng and Cheng, Ran},
	month = apr,
	year = {2021},
	file = {Springer Full Text PDF:files/265/Lin Á≠â„ÄÇ - 2021 - Adaptive dropout for high-dimensional expensive mu.pdf:application/pdf},
}

@inproceedings{li_manifold_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Manifold {Learning} {Inspired} {Mating} {Restriction} for {Evolutionary} {Constrained} {Multiobjective} {Optimization}},
	isbn = {978-3-030-72062-9},
	doi = {10.1007/978-3-030-72062-9_24},
	abstract = {Mating restriction strategies are capable of restricting the distribution of parent solutions for effective offspring generation in evolutionary algorithms (EAs). Studies have shown the importance of these strategies in improving the performance of EAs for multiobjective optimization. Our previous study proposed a specific manifold learning inspired mating restriction (MLMR) strategy. It has shown promising capability of solving multiobjective optimization problems (MOPs) with complicated Pareto set shapes. However, the effect of mating restriction strategies in solving constrained MOPs is yet to be well studied. Here, we investigate the effectiveness of MLMR for solving constrained MOPs. The MLMR strategy is embedded into some representative multiobjective EAs and tested on various benchmark constrained MOPs. Experimental results indicate the encouraging performance of MLMR in constrained multiobjective optimization.},
	language = {en},
	booktitle = {Evolutionary {Multi}-{Criterion} {Optimization}},
	publisher = {Springer International Publishing},
	author = {Li, Lianghao and He, Cheng and Cheng, Ran and Pan, Linqiang},
	editor = {Ishibuchi, Hisao and Zhang, Qingfu and Cheng, Ran and Li, Ke and Li, Hui and Wang, Handing and Zhou, Aimin},
	year = {2021},
	keywords = {Multiobjective optimization, Constraint handling, Mating restriction, Mating selection},
	pages = {296--307},
}

@inproceedings{cheng_bisexual_2012,
	title = {Bisexual {Evolution}: {A} {Novel} {Bisexual} {Evolutionary} {Framework} {Based} on the {Fisher}'s {Runaway} {Process}},
	shorttitle = {Bisexual evolution},
	doi = {10.1109/CEC.2012.6256463},
	abstract = {Sexual reproduction plays an important role in evolution. However, in classic genetic algorithms(GAs), the evolutionary process is only implemented on an unisexual population. Although some sexual selection schemes for GAs have been proposed, only limited studies are focused on detailed mechanisms in sexual selection. In this paper, we focus on the modeling of some significant components in sexual selection, including the concepts of male trait, female mating preference. Thereafter, a novel evolutionary framework is constructed based on these models. The theoretical principle of this framework is the famous mechanism called Fisher's runaway process. Numeric optimization is carried out to evaluate the newly proposed framework on a large number of benchmark functions used in CEC2005 Special Session. Comparing with a classic real-coded genetic algorithm, the novel framework outperforms it on most functions. Although this framework is very preliminary, it has shown good potential in solving optimization problems.},
	booktitle = {2012 {IEEE} {Congress} on {Evolutionary} {Computation}},
	author = {Cheng, Ran and Yao, Min and Xue, Xiaowei and Shen, Bin},
	month = jun,
	year = {2012},
	note = {ISSN: 1941-0026},
	keywords = {Evolutionary computation, Optimization, Educational institutions, Benchmark testing, Evolution (biology), Genetic algorithms, Biological cells},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:files/268/6256463.html:text/html},
}

@article{chen_revisiting_2021,
	title = {Revisiting {Self}-{Training} for {Few}-{Shot} {Learning} of {Language} {Model}},
	url = {http://arxiv.org/abs/2110.01256},
	abstract = {As unlabeled data carry rich task-relevant information, they are proven useful for few-shot learning of language model. The question is how to effectively make use of such data. In this work, we revisit the self-training technique for language model fine-tuning and present a state-of-the-art prompt-based few-shot learner, SFLM. Given two views of a text sample via weak and strong augmentation techniques, SFLM generates a pseudo label on the weakly augmented version. Then, the model predicts the same pseudo label when fine-tuned with the strongly augmented version. This simple approach is shown to outperform other state-of-the-art supervised and semi-supervised counterparts on six sentence classification and six sentence-pair classification benchmarking tasks. In addition, SFLM only relies on a few in-domain unlabeled data. We conduct a comprehensive analysis to demonstrate the robustness of our proposed approach under various settings, including augmentation techniques, model scale, and few-shot knowledge transfer across tasks.},
	urldate = {2021-11-23},
	journal = {arXiv:2110.01256 [cs]},
	author = {Chen, Yiming and Zhang, Yan and Zhang, Chen and Lee, Grandee and Cheng, Ran and Li, Haizhou},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.01256},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:files/278/2110.html:text/html;arXiv Fulltext PDF:files/279/Chen Á≠â„ÄÇ - 2021 - Revisiting Self-Training for Few-Shot Learning of .pdf:application/pdf},
}

@article{xiao_hybrid_2022,
	title = {Hybrid {Attention}-based {Transformer} {Block} {Model} for {Distant} {Supervision} {Relation} {Extraction}},
	volume = {470},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231221015174},
	doi = {10.1016/j.neucom.2021.10.037},
	abstract = {With an exponential explosive growth of various digital text information, it is challenging to efficiently obtain specific knowledge from massive unstructured text information. As one basic task for natural language processing (NLP), relation extraction (RE) aims to extract semantic relations between entity pairs based on the given text. To avoid manual labeling of datasets, distant supervision relation extraction (DSRE) has been widely used, aiming to utilize knowledge base to automatically annotate datasets. Unfortunately, this method heavily suffers from wrong labelling due to its underlying strong assumptions. To address this issue, we propose a new framework using hybrid attention-based Transformer block with multi-instance learning for DSRE. More specifically, the Transformer block is, for the first time, used as a sentence encoder, which mainly utilizes multi-head self-attention to capture syntactic information at the word level. Then, a novel sentence-level attention mechanism is proposed to calculate the bag representation, aiming to exploit all useful information in each sentence. Experimental results on the public dataset New York Times (NYT) demonstrate that the proposed approach can outperform the state-of-the-art algorithms on the adopted dataset, which verifies the effectiveness of our model on the DSRE task.},
	language = {en},
	urldate = {2021-11-23},
	journal = {Neurocomputing},
	author = {Xiao, Yan and Jin, Yaochu and Cheng, Ran and Hao, Kuangrong},
	month = jan,
	year = {2022},
	keywords = {Distant supervision relation extraction (DSRE), Sentence-level attention, Transformer block},
	pages = {29--39},
	file = {Â∑≤Êèê‰∫§ÁâàÊú¨:files/281/Xiao Á≠â„ÄÇ - 2022 - Hybrid attention-based transformer block model for.pdf:application/pdf;ScienceDirect Snapshot:files/282/S0925231221015174.html:text/html},
}

@article{xu_ternary_2022,
	title = {Ternary {Compression} for {Communication}-{Efficient} {Federated} {Learning}},
	volume = {33},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2020.3041185},
	abstract = {Learning over massive data stored in different locations is essential in many real-world applications. However, sharing data is full of challenges due to the increasing demands of privacy and security with the growing use of smart mobile devices and Internet of thing (IoT) devices. Federated learning provides a potential solution to privacy-preserving and secure machine learning, by means of jointly training a global model without uploading data distributed on multiple devices to a central server. However, most existing work on federated learning adopts machine learning models with full-precision weights, and almost all these models contain a large number of redundant parameters that do not need to be transmitted to the server, consuming an excessive amount of communication costs. To address this issue, we propose a federated trained ternary quantization (FTTQ) algorithm, which optimizes the quantized networks on the clients through a self-learning quantization factor. Theoretical proofs of the convergence of quantization factors, unbiasedness of FTTQ, as well as a reduced weight divergence are given. On the basis of FTTQ, we propose a ternary federated averaging protocol (T-FedAvg) to reduce the upstream and downstream communication of federated learning systems. Empirical experiments are conducted to train widely used deep learning models on publicly available data sets, and our results demonstrate that the proposed T-FedAvg is effective in reducing communication costs and can even achieve slightly better performance on non-IID data in contrast to the canonical federated learning algorithms.},
	number = {3},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Xu, Jinjin and Du, Wenli and Jin, Yaochu and He, Wangli and Cheng, Ran},
	month = mar,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Collaborative work, Communication efficiency, Computational modeling, Data models, deep learning, Distributed databases, federated learning, Quantization (signal), Servers, ternary coding, Training},
	pages = {1162--1176},
	file = {IEEE Xplore Abstract Record:files/284/9288933.html:text/html;Â∑≤Êèê‰∫§ÁâàÊú¨:files/285/Xu Á≠â„ÄÇ - 2022 - Ternary Compression for Communication-Efficient Fe.pdf:application/pdf},
}

@article{tian_evolutionary_2021,
	title = {Evolutionary {Large}-{Scale} {Multi}-{Objective} {Optimization}: {A} {Survey}},
	volume = {54},
	issn = {0360-0300},
	shorttitle = {Evolutionary {Large}-{Scale} {Multi}-{Objective} {Optimization}},
	url = {https://doi.org/10.1145/3470971},
	doi = {10.1145/3470971},
	abstract = {Multi-objective evolutionary algorithms (MOEAs) have shown promising performance in solving various optimization problems, but their performance may deteriorate drastically when tackling problems containing a large number of decision variables. In recent years, much effort been devoted to addressing the challenges brought by large-scale multi-objective optimization problems. This article presents a comprehensive survey of stat-of-the-art MOEAs for solving large-scale multi-objective optimization problems. We start with a categorization of these MOEAs into decision variable grouping based, decision space reduction based, and novel search strategy based MOEAs, discussing their strengths and weaknesses. Then, we review the benchmark problems for performance assessment and a few important and emerging applications of MOEAs for large-scale multi-objective optimization. Last, we discuss some remaining challenges and future research directions of evolutionary large-scale multi-objective optimization.},
	number = {8},
	urldate = {2022-03-02},
	journal = {ACM Computing Surveys},
	author = {Tian, Ye and Si, Langchun and Zhang, Xingyi and Cheng, Ran and He, Cheng and Tan, Kay Chen and Jin, Yaochu},
	month = oct,
	year = {2021},
	keywords = {evolutionary computation, large-scale optimization, Multi-objective optimization},
	pages = {174:1--174:34},
}

@article{he_adaptive_2022,
	title = {Adaptive {Offspring} {Generation} for {Evolutionary} {Large}-{Scale} {Multiobjective} {Optimization}},
	volume = {52},
	issn = {2168-2232},
	doi = {10.1109/TSMC.2020.3003926},
	abstract = {Offspring generation plays an important role in evolutionary multiobjective optimization. However, generating promising candidate solutions effectively in high-dimensional spaces is particularly challenging. To address this issue, we propose an adaptive offspring generation method for large-scale multiobjective optimization. First, a preselection strategy is proposed to select a balanced parent population, and then these parent solutions are used to construct direction vectors in the decision spaces for reproducing promising offspring solutions. Specifically, two kinds of direction vectors are adaptively used to generate offspring solutions. The first kind takes advantage of the dominated solutions to generate offspring solutions toward the Pareto optimal set (PS) for convergence enhancement, while the other kind uses those nondominated solutions to spread the solutions over the PS for diversity maintenance. The proposed offspring generation method can be embedded in many existing multiobjective evolutionary algorithms (EAs) for large-scale multiobjective optimization. Experiments are conducted to reveal the mechanism of our proposed adaptive reproduction strategy and validate its effectiveness. Experimental results on some large-scale multiobjective optimization problems have demonstrated the competitive performance of our proposed algorithm in comparison with five state-of-the-art large-scale EAs.},
	number = {2},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	author = {He, Cheng and Cheng, Ran and Yazdani, Danial},
	month = feb,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	keywords = {Adaptive offspring generation, Convergence, evolutionary algorithm (EA), Evolutionary computation, large-scale, Maintenance engineering, multiobjective optimization, Pareto optimization, Sociology},
	pages = {786--798},
	file = {IEEE Xplore Abstract Record:files/292/9138459.html:text/html},
}

@article{wang_end--end_2021,
	title = {End-to-{End} {Dense} {Video} {Captioning} with {Parallel} {Decoding}},
	url = {http://arxiv.org/abs/2108.07781},
	abstract = {Dense video captioning aims to generate multiple associated captions with their temporal locations from the video. Previous methods follow a sophisticated "localize-then-describe" scheme, which heavily relies on numerous hand-crafted components. In this paper, we proposed a simple yet effective framework for end-to-end dense video captioning with parallel decoding (PDVC), by formulating the dense caption generation as a set prediction task. In practice, through stacking a newly proposed event counter on the top of a transformer decoder, the PDVC precisely segments the video into a number of event pieces under the holistic understanding of the video content, which effectively increases the coherence and readability of predicted captions. Compared with prior arts, the PDVC has several appealing advantages: (1) Without relying on heuristic non-maximum suppression or a recurrent event sequence selection network to remove redundancy, PDVC directly produces an event set with an appropriate size; (2) In contrast to adopting the two-stage scheme, we feed the enhanced representations of event queries into the localization head and caption head in parallel, making these two sub-tasks deeply interrelated and mutually promoted through the optimization; (3) Without bells and whistles, extensive experiments on ActivityNet Captions and YouCook2 show that PDVC is capable of producing high-quality captioning results, surpassing the state-of-the-art two-stage methods when its localization accuracy is on par with them. Code is available at https://github.com/ttengwang/PDVC.},
	urldate = {2022-03-02},
	journal = {arXiv:2108.07781 [cs]},
	author = {Wang, Teng and Zhang, Ruimao and Lu, Zhichao and Zheng, Feng and Cheng, Ran and Luo, Ping},
	month = nov,
	year = {2021},
	note = {arXiv: 2108.07781},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:files/316/Wang Á≠â„ÄÇ - 2021 - End-to-End Dense Video Captioning with Parallel De.pdf:application/pdf;arXiv.org Snapshot:files/317/2108.html:text/html},
}

@article{huang_fapn_2021,
	title = {{FaPN}: {Feature}-aligned {Pyramid} {Network} for {Dense} {Image} {Prediction}},
	shorttitle = {{FaPN}},
	url = {http://arxiv.org/abs/2108.07058},
	abstract = {Recent advancements in deep neural networks have made remarkable leap-forwards in dense image prediction. However, the issue of feature alignment remains as neglected by most existing approaches for simplicity. Direct pixel addition between upsampled and local features leads to feature maps with misaligned contexts that, in turn, translate to mis-classifications in prediction, especially on object boundaries. In this paper, we propose a feature alignment module that learns transformation offsets of pixels to contextually align upsampled higher-level features; and another feature selection module to emphasize the lower-level features with rich spatial details. We then integrate these two modules in a top-down pyramidal architecture and present the Feature-aligned Pyramid Network (FaPN). Extensive experimental evaluations on four dense prediction tasks and four datasets have demonstrated the efficacy of FaPN, yielding an overall improvement of 1.2 - 2.6 points in AP / mIoU over FPN when paired with Faster / Mask R-CNN. In particular, our FaPN achieves the state-of-the-art of 56.7\% mIoU on ADE20K when integrated within Mask-Former. The code is available from https://github.com/EMI-Group/FaPN.},
	urldate = {2022-03-02},
	journal = {arXiv:2108.07058 [cs]},
	author = {Huang, Shihua and Lu, Zhichao and Cheng, Ran and He, Cheng},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.07058},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}
