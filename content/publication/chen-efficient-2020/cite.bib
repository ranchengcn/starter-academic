@inproceedings{chen_efficient_2020,
 abstract = {Deep learning has achieved enormous breakthroughs in the field of image recognition. However, due to the time-consuming and error-prone process in discovering novel neural architecture, it remains a challenge for designing a specific network in handling a particular task. Hence, many automated neural architecture search methods are proposed to find suitable deep neural network architecture for a specific task without human experts. Nevertheless, these methods are still computationally/economically expensive, since they require a vast amount of computing resource and/or computational time. In this paper, we propose several network morphism mutation operators with extra noise, and further redesign the macro-architecture based on the classical network. The proposed methods are embedded in an evolutionary algorithm and tested on CIFAR-10 classification task. Experimental results indicate the capability of our proposed method in discovering powerful neural architecture which has achieved a classification error 2.55% with only 4.7M parameters on CIFAR-10 within 12 GPU-hours.},
 address = {Singapore},
 author = {Chen, Yiming and Pan, Tianci and He, Cheng and Cheng, Ran},
 booktitle = {Bio-inspired Computing: Theories and Applications},
 doi = {10.1007/978-981-15-3415-7_41},
 editor = {Pan, Linqiang and Liang, Jing and Qu, Boyang},
 file = {Springer Full Text PDF:/home/bill/Zotero/storage/ZI6FSY28/Chen et al. - 2020 - Efficient Evolutionary Deep Neural Architecture Se.pdf:application/pdf},
 isbn = {9789811534157},
 keywords = {Evolutionary algorithm, Neural architecture search, Network morphism},
 language = {en},
 pages = {497--508},
 publisher = {Springer},
 series = {Communications in Computer and Information Science},
 title = {Efficient Evolutionary Deep Neural Architecture Search (NAS) by Noisy Network Morphism Mutation},
 year = {2020}
}

