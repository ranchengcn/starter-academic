@article{zhang_efficient_2021,
 abstract = {The performance of deep neural networks is heavily dependent on its architecture and various neural architecture search strategies have been developed for automated network architecture design. Recently, evolutionary neural architecture search (EvoNAS) has received increasing attention due to the attractive global optimization capability of evolutionary algorithms. However, EvoNAS suffers from extremely high computational costs because a large number of performance evaluations are usually required in evolutionary optimization, and training deep neural networks is itself computationally very expensive. To address this issue, this article proposes a computationally efficient framework for the evolutionary search of convolutional networks based on a directed acyclic graph, in which parents are randomly sampled and trained on each mini-batch of training data. In addition, a node inheritance strategy is adopted so that the fitness of all offspring individuals can be evaluated without training them. Finally, we encode a channel attention mechanism in the search space to enhance the feature processing capability of the evolved neural networks. We evaluate the proposed algorithm on the widely used datasets, in comparison with 30 state-of-the-art peer algorithms. Our experimental results show that the proposed algorithm is not only computationally much more efficient but also highly competitive in learning performance.},
 annote = {Conference Name: IEEE Transactions on Evolutionary Computation},
 author = {Zhang, Haoyu and Jin, Yaochu and Cheng, Ran and Hao, Kuangrong},
 doi = {10.1109/TEVC.2020.3040272},
 issn = {1941-0026},
 journal = {IEEE Transactions on Evolutionary Computation},
 keywords = {Sociology, Optimization, Statistics, Computer architecture, neural architecture search (NAS), Neural networks, Training, Attention mechanism, convolutional neural networks (CNNs), evolutionary optimization, Graphics processing units, node inheritance},
 number = {2},
 pages = {371--385},
 title = {Efficient Evolutionary Search of Attention Convolutional Networks via Sampled Training and Node Inheritance},
 volume = {25},
 year = {2021}
}

