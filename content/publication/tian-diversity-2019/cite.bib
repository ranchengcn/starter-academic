@article{tian_diversity_2019,
 abstract = {Diversity preservation plays an important role in the design of multi-objective evolutionary algorithms, but the diversity performance assessment of these algorithms remains challenging. To address this issue, this paper proposes a performance metric and a multi-objective test suite for the diversity assessment of multiobjective evolutionary algorithms. The proposed metric assesses both the evenness and spread of a solution set by projecting it to a lower-dimensional hypercube and calculating the "volume" of the projected solution set. The proposed test suite contains eight benchmark problems, which pose stiff challenges for existing algorithms to obtain a diverse solution set. Experimental studies demonstrate that the proposed metric can assess the diversity of a solution set more precisely than existing ones, and the proposed test suite can be used to effectively distinguish between algorithms with respect to their diversity performance.},
 annote = {Conference Name: IEEE Computational Intelligence Magazine},
 author = {Tian, Ye and Cheng, Ran and Zhang, Xingyi and Li, Miqing and Jin, Yaochu},
 doi = {10.1109/MCI.2019.2919398},
 issn = {1556-6048},
 journal = {IEEE Computational Intelligence Magazine},
 keywords = {Evolutionary computation, Benchmark testing, Hypercubes},
 number = {3},
 pages = {61--74},
 shorttitle = {Diversity Assessment of Multi-Objective Evolutionary Algorithms},
 title = {Diversity Assessment of Multi-Objective Evolutionary Algorithms: Performance Metric and Benchmark Problems [Research Frontier]},
 volume = {14},
 year = {2019}
}

